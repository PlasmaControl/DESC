{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# How to use Multiple Devices\n",
    "\n",
    "In this tutorial, we will see how to use multiple devices to run DESC. This will make the optimization problem scalable to computing clusters.\n",
    "\n",
    "This tutorials will not be able to run on a Jupyter Notebook, so we will provide the content of the script here but run an underlying python script to show the results.\n",
    "\n",
    "## Solving Equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Add the path to the parent directory to augment search for module\n",
       "sys.path.insert(0, os.path.abspath(\".\"))\n",
       "sys.path.append(os.path.abspath(\"../../../\"))\n",
       "sys.path.append(os.path.abspath(\"../../../../\"))\n",
       "\n",
       "import numpy as np\n",
       "from mpi4py import MPI\n",
       "\n",
       "from desc import _set_cpu_count, set_device\n",
       "\n",
       "kind = \"cpu\"  # or \"gpu\"\n",
       "num_device = 2\n",
       "# ====== Using CPUs ======\n",
       "# These will be used for diving the single CPU into multiple virtual CPUs\n",
       "# such that JAX and XLA thinks there are multiple devices\n",
       "if kind == \"cpu\":\n",
       "    # !!! If you have multiple CPUs, you shouldn't call `_set_cpu_count` !!!\n",
       "    _set_cpu_count(num_device)\n",
       "    set_device(\"cpu\", num_device=num_device, mpi=MPI)\n",
       "\n",
       "# ====== Using GPUs ======\n",
       "# When we have multiple processes using the same devices (for example, 3 processes\n",
       "# using 3 GPUs), each process will try to pre-allocate 75% of the GPU memory which will\n",
       "# cause the memory allocation to fail. To avoid this, we can set the allocator to `platform`\n",
       "# such that there is no pre-allocation. This is a bit conservative (and probably there is room\n",
       "# for improvement), but if a process needs more memory, it can use more memory on the fly.\n",
       "elif kind == \"gpu\":\n",
       "    os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
       "    set_device(\"gpu\", num_device=num_device)\n",
       "\n",
       "from desc import config as desc_config\n",
       "from desc.backend import jax, print_backend_info\n",
       "from desc.examples import get\n",
       "from desc.grid import LinearGrid\n",
       "from desc.objectives import ForceBalance, ObjectiveFunction\n",
       "from desc.objectives.getters import get_fixed_boundary_constraints\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    rank = MPI.COMM_WORLD.Get_rank()\n",
       "    size = MPI.COMM_WORLD.Get_size()\n",
       "    if rank == 0:\n",
       "        print(f\"====== TOTAL OF {size} RANKS ======\")\n",
       "\n",
       "    # see which rank is running on which device\n",
       "    # Note: JAX has 2 functions for this: `jax.devices()` and `jax.local_devices()`\n",
       "    # `jax.devices()` will return all devices available to JAX, while `jax.local_devices()`\n",
       "    # will return only the devices that are available to the current process. This is\n",
       "    # useful when you have multiple processes running on multiple nodes and you want\n",
       "    # to see which devices are available to each process.\n",
       "    if desc_config[\"kind\"] == \"gpu\":\n",
       "        print(\n",
       "            f\"Rank {rank} can see {jax.local_devices(backend='gpu')} \"\n",
       "            f\"and {jax.local_devices(backend='cpu')}\\n\"\n",
       "        )\n",
       "    else:\n",
       "        print(f\"Rank {rank} can see {jax.local_devices(backend='cpu')}\\n\")\n",
       "\n",
       "    if rank == 0:\n",
       "        print(\"====== BACKEND INFO ======\")\n",
       "        print_backend_info()\n",
       "        print(\"\\n\")\n",
       "\n",
       "    eq = get(\"HELIOTRON\")\n",
       "    if desc_config[\"kind\"] == \"cpu\":\n",
       "        # for local testing use lower resolution\n",
       "        eq.change_resolution(M=3, N=2, M_grid=6, N_grid=4)\n",
       "\n",
       "    # setup 2 grids for 2 objectives covering different flux surfaces\n",
       "    rhos = np.linspace(0.1, 1.0, eq.L_grid)\n",
       "    grid1 = LinearGrid(\n",
       "        rho=rhos[: rhos.size // 2],\n",
       "        M=eq.M_grid,\n",
       "        N=eq.N_grid,\n",
       "        NFP=eq.NFP,\n",
       "    )\n",
       "    grid2 = LinearGrid(\n",
       "        rho=rhos[rhos.size // 2 :],\n",
       "        M=eq.M_grid,\n",
       "        N=eq.N_grid,\n",
       "        NFP=eq.NFP,\n",
       "    )\n",
       "    obj = ObjectiveFunction(\n",
       "        [\n",
       "            ForceBalance(eq, grid=grid1, device_id=0),\n",
       "            ForceBalance(eq, grid=grid2, device_id=1),\n",
       "        ],\n",
       "        mpi=MPI,\n",
       "        deriv_mode=\"blocked\",\n",
       "    )\n",
       "    obj.build()\n",
       "    cons = get_fixed_boundary_constraints(eq)\n",
       "\n",
       "    # Until this line, the code is performed on all ranks, so it might print some\n",
       "    # information multiple times. The following part will only be performed on the\n",
       "    # master rank\n",
       "\n",
       "    # this context manager will put the workers in a loop to listen to the master\n",
       "    # to compute the objective function and its derivatives\n",
       "    with obj:\n",
       "        # apart from cost evaluation and derivatives, everything else will be only\n",
       "        # performed on the master rank\n",
       "        if rank == 0:\n",
       "            eq.solve(\n",
       "                objective=obj,\n",
       "                constraints=cons,\n",
       "                maxiter=10,\n",
       "                ftol=0,\n",
       "                gtol=0,\n",
       "                xtol=0,\n",
       "                verbose=3,\n",
       "            )\n",
       "\n",
       "    # if you put a code here, it will be performed on all ranks\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the content of mpi-eq-solve.py\n",
    "with open(\"mpi-tutorials/mpi-eq-solve.py\", \"r\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "Markdown(f\"```python\\n{code}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== TOTAL OF 2 RANKS ======\n",
      "Rank 0 can see [CpuDevice(id=0), CpuDevice(id=1)]\n",
      "\n",
      "====== BACKEND INFO ======\n",
      "DESC version=0.15.0+189.g6c33270c1.dirty.\n",
      "Using JAX backend: jax version=0.6.2, jaxlib version=0.6.2, dtype=float64.\n",
      "Using 2 CPUs with 19.06 GB total available memory:\n",
      "\t CPU : 0  13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "\t CPU : 1  13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "\n",
      "Note: The backend information assumes that the user has 1 process per CPU (node). Using multiple processes per CPU (node) is not the most efficient way to use MPI with purely CPUs.\n",
      "\n",
      "\n",
      "Rank 1 can see [CpuDevice(id=0), CpuDevice(id=1)]\n",
      "\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Putting objective force on device 1\n",
      "------------------------------------------------------------\n",
      "Rank 0 will run objective(s): ['ForceBalance']\n",
      "Rank 1 will run objective(s): ['ForceBalance']\n",
      "------------------------------------------------------------\n",
      "Building objective: lcfs R\n",
      "Building objective: lcfs Z\n",
      "Building objective: fixed Psi\n",
      "Building objective: fixed pressure\n",
      "Building objective: fixed iota\n",
      "Building objective: fixed sheet current\n",
      "Building objective: self_consistency R\n",
      "Building objective: self_consistency Z\n",
      "Building objective: lambda gauge\n",
      "Building objective: axis R self consistency\n",
      "Building objective: axis Z self consistency\n",
      "\u001b[32mTimer: Objective build = 768 ms\u001b[0m\n",
      "\u001b[32mTimer: LinearConstraintProjection build = 2.16 sec\u001b[0m\n",
      "Number of parameters: 551\n",
      "Number of objectives: 8424\n",
      "\u001b[32mTimer: Initializing the optimization = 2.96 sec\u001b[0m\n",
      "\n",
      "Starting optimization\n",
      "Using method: lsq-exact\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1          8.421e-01                                    6.217e-01   \n",
      "       1              2          2.599e-01      5.822e-01      3.670e-01      2.179e-01   \n",
      "       2              3          1.183e-01      1.416e-01      2.557e-01      2.515e-01   \n",
      "       3              4          5.716e-02      6.110e-02      4.079e-01      1.491e-01   \n",
      "       4              5          3.971e-02      1.745e-02      3.098e-01      1.289e-01   \n",
      "       5              7          2.335e-02      1.636e-02      8.984e-02      1.444e-01   \n",
      "       6              9          1.465e-02      8.698e-03      1.920e-02      1.263e-01   \n",
      "       7             10          1.058e-02      4.076e-03      2.100e-02      9.828e-02   \n",
      "       8             12          7.898e-04      9.785e-03      1.084e-02      1.536e-02   \n",
      "       9             13          5.671e-04      2.227e-04      1.678e-02      4.195e-03   \n",
      "      10             16          5.368e-04      3.027e-05      3.373e-03      1.381e-03   \n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 5.368e-04\n",
      "         Total delta_x: 8.143e-01\n",
      "         Iterations: 10\n",
      "         Function evaluations: 16\n",
      "         Jacobian evaluations: 11\n",
      "\u001b[32mTimer: Solution time = 23.3 sec\u001b[0m\n",
      "\u001b[32mTimer: Avg time per step = 2.11 sec\u001b[0m\n",
      "==============================================================================================================\n",
      "                                                                 Start  -->   End\n",
      "Total (sum of squares):                                      8.421e-01  -->   5.368e-04, \n",
      "Maximum absolute Force error:                                2.169e+05  -->   8.279e+03 (N)\n",
      "Minimum absolute Force error:                                1.091e-10  -->   1.310e-10 (N)\n",
      "Average absolute Force error:                                4.139e+04  -->   1.043e+03 (N)\n",
      "Maximum absolute Force error:                                1.744e-02  -->   6.659e-04 (normalized)\n",
      "Minimum absolute Force error:                                8.774e-18  -->   1.054e-17 (normalized)\n",
      "Average absolute Force error:                                3.329e-03  -->   8.390e-05 (normalized)\n",
      "Maximum absolute Force error:                                1.149e+07  -->   2.085e+05 (N)\n",
      "Minimum absolute Force error:                                2.439e-12  -->   3.449e-12 (N)\n",
      "Average absolute Force error:                                1.017e+05  -->   3.559e+03 (N)\n",
      "Maximum absolute Force error:                                9.238e-01  -->   1.677e-02 (normalized)\n",
      "Minimum absolute Force error:                                1.962e-19  -->   2.774e-19 (normalized)\n",
      "Average absolute Force error:                                8.181e-03  -->   2.862e-04 (normalized)\n",
      "R boundary error:                                            0.000e+00  -->   0.000e+00 (m)\n",
      "Z boundary error:                                            0.000e+00  -->   0.000e+00 (m)\n",
      "Fixed Psi error:                                             0.000e+00  -->   0.000e+00 (Wb)\n",
      "Fixed pressure profile error:                                0.000e+00  -->   0.000e+00 (Pa)\n",
      "Fixed iota profile error:                                    0.000e+00  -->   0.000e+00 (dimensionless)\n",
      "Fixed sheet current error:                                   0.000e+00  -->   0.000e+00 (~)\n",
      "==============================================================================================================\n",
      "\n",
      "Rank 1 STOPPING\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mpirun -n 2 python mpi-tutorials/mpi-eq-solve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other Objectives\n",
    "Above we used MPI for force balance objective, but we can also use it for general optimization.\n",
    "\n",
    "**Note:** Currently, if the optimizer solves the equilibrium at each step, this equilibrium solve cannot use MPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Add the path to the parent directory to augment search for module\n",
       "sys.path.insert(0, os.path.abspath(\".\"))\n",
       "sys.path.append(os.path.abspath(\"../../../\"))\n",
       "sys.path.append(os.path.abspath(\"../../../../\"))\n",
       "\n",
       "from mpi4py import MPI\n",
       "\n",
       "from desc import _set_cpu_count, set_device\n",
       "\n",
       "kind = \"cpu\"  # or \"gpu\"\n",
       "num_device = 2\n",
       "# ====== Using CPUs ======\n",
       "# These will be used for diving the single CPU into multiple virtual CPUs\n",
       "# such that JAX and XLA thinks there are multiple devices\n",
       "if kind == \"cpu\":\n",
       "    # !!! If you have multiple CPUs, you shouldn't call `_set_cpu_count` !!!\n",
       "    _set_cpu_count(num_device)\n",
       "    set_device(\"cpu\", num_device=num_device, mpi=MPI)\n",
       "\n",
       "# ====== Using GPUs ======\n",
       "# When we have multiple processes using the same devices (for example, 3 processes\n",
       "# using 3 GPUs), each process will try to pre-allocate 75% of the GPU memory which will\n",
       "# cause the memory allocation to fail. To avoid this, we can set the allocator to `platform`\n",
       "# such that there is no pre-allocation. This is a bit conservative (and probably there is room\n",
       "# for improvement), but if a process needs more memory, it can use more memory on the fly.\n",
       "elif kind == \"gpu\":\n",
       "    os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
       "    set_device(\"gpu\", num_device=num_device)\n",
       "\n",
       "\n",
       "import numpy as np\n",
       "\n",
       "from desc import config as desc_config\n",
       "from desc.backend import jax, jnp, print_backend_info\n",
       "from desc.examples import get\n",
       "from desc.grid import LinearGrid\n",
       "from desc.objectives import (\n",
       "    AspectRatio,\n",
       "    FixBoundaryR,\n",
       "    FixBoundaryZ,\n",
       "    FixCurrent,\n",
       "    FixPressure,\n",
       "    FixPsi,\n",
       "    ForceBalance,\n",
       "    ObjectiveFunction,\n",
       "    QuasisymmetryTwoTerm,\n",
       ")\n",
       "from desc.optimize import Optimizer\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    rank = MPI.COMM_WORLD.Get_rank()\n",
       "    size = MPI.COMM_WORLD.Get_size()\n",
       "    if rank == 0:\n",
       "        print(f\"====== TOTAL OF {size} RANKS ======\")\n",
       "\n",
       "    # see which rank is running on which device\n",
       "    # Note: JAX has 2 functions for this: `jax.devices()` and `jax.local_devices()`\n",
       "    # `jax.devices()` will return all devices available to JAX, while `jax.local_devices()`\n",
       "    # will return only the devices that are available to the current process. This is\n",
       "    # useful when you have multiple processes running on multiple nodes and you want\n",
       "    # to see which devices are available to each process.\n",
       "    if desc_config[\"kind\"] == \"gpu\":\n",
       "        print(\n",
       "            f\"Rank {rank} is running on {jax.local_devices(backend='gpu')} \"\n",
       "            f\"and {jax.local_devices(backend='cpu')}\\n\"\n",
       "        )\n",
       "    else:\n",
       "        print(f\"Rank {rank} is running on {jax.local_devices(backend='cpu')}\\n\")\n",
       "\n",
       "    if rank == 0:\n",
       "        print(\"====== BACKEND INFO ======\")\n",
       "        print_backend_info()\n",
       "        print(\"\\n\")\n",
       "\n",
       "    eq = get(\"precise_QA\")\n",
       "    if desc_config[\"kind\"] == \"cpu\":\n",
       "        eq.change_resolution(M=3, N=2, M_grid=6, N_grid=4)\n",
       "\n",
       "    # create two grids with different rho values, this will effectively separate\n",
       "    # the quasisymmetry objective into two parts\n",
       "    grid1 = LinearGrid(\n",
       "        M=eq.M_grid,\n",
       "        N=eq.N_grid,\n",
       "        NFP=eq.NFP,\n",
       "        rho=jnp.linspace(0.2, 0.5, 4),\n",
       "        sym=True,\n",
       "    )\n",
       "    grid2 = LinearGrid(\n",
       "        M=eq.M_grid,\n",
       "        N=eq.N_grid,\n",
       "        NFP=eq.NFP,\n",
       "        rho=jnp.linspace(0.6, 1.0, 6),\n",
       "        sym=True,\n",
       "    )\n",
       "\n",
       "    # when using parallel objectives, the user needs to supply the device_id\n",
       "    obj1 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid1, device_id=0)\n",
       "    obj2 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid2, device_id=1)\n",
       "    obj3 = AspectRatio(eq=eq, target=8, weight=100, device_id=0)\n",
       "    objs = [obj1, obj2, obj3]\n",
       "\n",
       "    # Parallel objective function needs the MPI communicator\n",
       "    # If you don't specify `deriv_mode=blocked`, you will get a warning and DESC will\n",
       "    # automatically switch to `blocked`.\n",
       "    objective = ObjectiveFunction(\n",
       "        objs, deriv_mode=\"blocked\", mpi=MPI, rank_per_objective=np.array([0, 1, 0])\n",
       "    )\n",
       "    if rank == 0:\n",
       "        objective.build(verbose=3)\n",
       "    else:\n",
       "        objective.build(verbose=0)\n",
       "\n",
       "    # we will fix some modes as usual\n",
       "    k = 1\n",
       "    R_modes = np.vstack(\n",
       "        (\n",
       "            [0, 0, 0],\n",
       "            eq.surface.R_basis.modes[\n",
       "                np.max(np.abs(eq.surface.R_basis.modes), 1) > k, :\n",
       "            ],\n",
       "        )\n",
       "    )\n",
       "    Z_modes = eq.surface.Z_basis.modes[\n",
       "        np.max(np.abs(eq.surface.Z_basis.modes), 1) > k, :\n",
       "    ]\n",
       "    constraints = (\n",
       "        ForceBalance(eq=eq),\n",
       "        FixBoundaryR(eq=eq, modes=R_modes),\n",
       "        FixBoundaryZ(eq=eq, modes=Z_modes),\n",
       "        FixPressure(eq=eq),\n",
       "        FixPsi(eq=eq),\n",
       "        FixCurrent(eq=eq),\n",
       "    )\n",
       "    optimizer = Optimizer(\"proximal-lsq-exact\")\n",
       "\n",
       "    # Until this line, the code is performed on all ranks, so it might print some\n",
       "    # information multiple times. The following part will only be performed on the\n",
       "    # master rank\n",
       "\n",
       "    # this context manager will put the workers in a loop to listen to the master\n",
       "    # to compute the objective function and its derivatives\n",
       "    with objective:\n",
       "        # apart from cost evaluation and derivatives, everything else will be only\n",
       "        # performed on the master rank\n",
       "        if rank == 0:\n",
       "            eq.optimize(\n",
       "                objective=objective,\n",
       "                constraints=constraints,\n",
       "                optimizer=optimizer,\n",
       "                maxiter=3,\n",
       "                verbose=3,\n",
       "                options={\n",
       "                    \"initial_trust_ratio\": 1.0,\n",
       "                },\n",
       "            )\n",
       "\n",
       "    # if you put a code here, it will be performed on all ranks\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the content of mpi-proximal.py\n",
    "with open(\"mpi-tutorials/mpi-proximal.py\", \"r\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "Markdown(f\"```python\\n{code}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 is running on [CpuDevice(id=0), CpuDevice(id=1)]\n",
      "\n",
      "====== TOTAL OF 2 RANKS ======\n",
      "Rank 0 is running on [CpuDevice(id=0), CpuDevice(id=1)]\n",
      "\n",
      "====== BACKEND INFO ======\n",
      "DESC version=0.15.0+189.g6c33270c1.dirty.\n",
      "Using JAX backend: jax version=0.6.2, jaxlib version=0.6.2, dtype=float64.\n",
      "Using 2 CPUs with 19.37 GB total available memory:\n",
      "\t CPU : 0  13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "\t CPU : 1  13th Gen Intel(R) Core(TM) i9-13900HX\n",
      "\n",
      "Note: The backend information assumes that the user has 1 process per CPU (node). Using multiple processes per CPU (node) is not the most efficient way to use MPI with purely CPUs.\n",
      "\n",
      "\n",
      "Building objective: QS two-term\n",
      "Precomputing transforms\n",
      "\u001b[32mTimer: Precomputing transforms = 771 ms\u001b[0m\n",
      "Building objective: QS two-term\n",
      "Precomputing transforms\n",
      "\u001b[32mTimer: Precomputing transforms = 656 ms\u001b[0m\n",
      "Putting objective QS two-term on device 1\n",
      "Building objective: aspect ratio\n",
      "Precomputing transforms\n",
      "\u001b[32mTimer: Precomputing transforms = 636 ms\u001b[0m\n",
      "------------------------------------------------------------\n",
      "Rank 0 will run objective(s): ['QuasisymmetryTwoTerm', 'AspectRatio']\n",
      "Rank 1 will run objective(s): ['QuasisymmetryTwoTerm']\n",
      "------------------------------------------------------------\n",
      "\u001b[32mTimer: Objective build = 2.52 sec\u001b[0m\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "\u001b[32mTimer: Precomputing transforms = 886 ms\u001b[0m\n",
      "\u001b[32mTimer: Objective build = 931 ms\u001b[0m\n",
      "\u001b[32mTimer: Objective build = 1.11 ms\u001b[0m\n",
      "\u001b[32mTimer: Eq Update LinearConstraintProjection build = 2.18 sec\u001b[0m\n",
      "\u001b[32mTimer: Proximal projection build = 4.57 sec\u001b[0m\n",
      "Building objective: lcfs R\n",
      "Building objective: lcfs Z\n",
      "Building objective: fixed pressure\n",
      "Building objective: fixed Psi\n",
      "Building objective: fixed current\n",
      "\u001b[32mTimer: Objective build = 433 ms\u001b[0m\n",
      "\u001b[32mTimer: LinearConstraintProjection build = 969 ms\u001b[0m\n",
      "Number of parameters: 8\n",
      "Number of objectives: 631\n",
      "\u001b[32mTimer: Initializing the optimization = 6.01 sec\u001b[0m\n",
      "\n",
      "Starting optimization\n",
      "Using method: proximal-lsq-exact\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1          2.005e+04                                    1.926e+02   \n",
      "       1              4          8.123e+03      1.193e+04      4.964e-02      9.847e+01   \n",
      "       2              5          2.617e+03      5.507e+03      5.877e-02      6.065e+01   \n",
      "       3              7          7.564e+02      1.860e+03      7.212e-02      3.935e+00   \n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 7.564e+02\n",
      "         Total delta_x: 7.271e-02\n",
      "         Iterations: 3\n",
      "         Function evaluations: 7\n",
      "         Jacobian evaluations: 4\n",
      "\u001b[32mTimer: Solution time = 31.5 sec\u001b[0m\n",
      "\u001b[32mTimer: Avg time per step = 7.89 sec\u001b[0m\n",
      "==============================================================================================================\n",
      "                                                                 Start  -->   End\n",
      "Total (sum of squares):                                      2.005e+04  -->   7.564e+02, \n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        4.038e-01  -->   1.333e+00 (T^3)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        2.569e-04  -->   2.875e-04 (T^3)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.039e-01  -->   2.474e-01 (T^3)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        4.406e-01  -->   1.455e+00 (normalized)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        2.803e-04  -->   3.137e-04 (normalized)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.134e-01  -->   2.699e-01 (normalized)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        9.615e-01  -->   2.043e+00 (T^3)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        3.670e-04  -->   1.044e-02 (T^3)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.474e-01  -->   3.819e-01 (T^3)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        1.049e+00  -->   2.229e+00 (normalized)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        4.004e-04  -->   1.139e-02 (normalized)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.609e-01  -->   4.167e-01 (normalized)\n",
      "Aspect ratio:                                                6.002e+00  -->   7.856e+00 (dimensionless)\n",
      "Maximum absolute Force error:                                1.435e+05  -->   2.352e+04 (N)\n",
      "Minimum absolute Force error:                                1.480e+00  -->   6.889e+00 (N)\n",
      "Average absolute Force error:                                7.215e+03  -->   2.171e+03 (N)\n",
      "Maximum absolute Force error:                                1.026e-01  -->   1.681e-02 (normalized)\n",
      "Minimum absolute Force error:                                1.058e-06  -->   4.925e-06 (normalized)\n",
      "Average absolute Force error:                                5.157e-03  -->   1.552e-03 (normalized)\n",
      "R boundary error:                                            0.000e+00  -->   4.600e-19 (m)\n",
      "Z boundary error:                                            0.000e+00  -->   3.469e-18 (m)\n",
      "Fixed pressure profile error:                                0.000e+00  -->   0.000e+00 (Pa)\n",
      "Fixed Psi error:                                             0.000e+00  -->   0.000e+00 (Wb)\n",
      "Fixed current profile error:                                 0.000e+00  -->   0.000e+00 (A)\n",
      "==============================================================================================================\n",
      "\n",
      "Rank 1 STOPPING\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mpirun -n 2 python mpi-tutorials/mpi-proximal.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Slurm for Multi-Node and Multi-Process Scripts\n",
    "\n",
    "**Note :** These instructions may differ for the cluster you are trying to use. The reason we give this example is to set some terminology for users that are not familiar with multi-node and multi-processing.\n",
    "\n",
    "**Note :** For more details, one can check Princeton University Research Computing page [here](https://researchcomputing.princeton.edu/support/knowledge-base/slurm#Multinode--Multithreaded-Jobs).\n",
    "\n",
    "One needs to use proper slurm script to run parallel code on a cluster. Here, we will give an example in which we use 2 nodes, 8 processes per node and 4 CPU cores per process. *Node* means the actual CPU chip, so we will have 2 CPUs or you can think of it as, we will have 2 computers that are connected to each other. We will have 16 processes and 64 CPU cores in total. Additionally, you can specify number of GPUs per node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=mpi-example        # create a short name for your job\n",
    "#SBATCH --nodes=2                # node count\n",
    "#SBATCH --ntasks-per-node=8      # total number of tasks per node\n",
    "#SBATCH --cpus-per-task=4        # cpu-cores per task (>1 if multi-threaded tasks)\n",
    "#SBATCH --mem-per-cpu=4G         # memory per cpu-core (4G is default)\n",
    "#SBATCH --time=00:10:00          # total run time limit (HH:MM:SS)\n",
    "#SBATCH --gres=gpu:4             # number of GPUs per node (in this case 8 GPUs in total)\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n",
    "module purge\n",
    "\n",
    "# module names and version might be different for clusters\n",
    "module load anaconda3/2024.6\n",
    "module load openmpi/gcc/4.1.6\n",
    "\n",
    "# activate the environment that has DESC requirements\n",
    "# as well as proper mpi4py installation\n",
    "conda activate mpi-env\n",
    "\n",
    "srun python your-script.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using MPI with multiple nodes, each process will see 1 CPU (with multiple cores), and if you requested GPUs, only the GPUs connected to that CPU will be visible to your program. With this in mind, for example, if you want to use 2 nodes, and 3 GPUs per nodes with 3 processes per node, you can use 6 objectives in this way.\n",
    "\n",
    "```python\n",
    "\n",
    "# each node will see 3 GPUs\n",
    "num_device = 3\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "set_device(\"gpu\", num_device=num_device)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "# this will run on node 1, GPU 0 (rank=0)\n",
    "obj1 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid1, device_id=0)\n",
    "# this will run on node 1, GPU 1 (rank=1)\n",
    "obj2 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid2, device_id=1)\n",
    "# this will run on node 1, GPU 2 (rank=2)\n",
    "obj3 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid3, device_id=2)\n",
    "# this will run on node 2, GPU 0 (rank=3)\n",
    "obj4 = AspectRatio(eq=eq, target=8, weight=100, device_id=0)\n",
    "# this will run on node 2, GPU 1 (rank=4)\n",
    "obj5 = Objective(..., device_id=1)\n",
    "# this will run on node 2, GPU 2 (rank=5)\n",
    "obj6 = Objective(..., device_id=2)\n",
    "objs = [obj1, obj2, obj3, obj4, obj5, obj6]\n",
    "\n",
    "# Parallel objective function needs the MPI communicator\n",
    "objective = ObjectiveFunction(objs, deriv_mode=\"blocked\", mpi=MPI)\n",
    "\n",
    "```\n",
    "\n",
    "When you write your script for multiple nodes, the number of devices and the device IDs must be selected as if there is only 1 node and only the local GPUs are visible. Other nodes will be used through `rank` of MPI communicator.\n",
    "\n",
    "**Note: Most clusters have multiple GPUs connected to each node, so before using multiple nodes, use all the GPUs available to that node. Multi-node communication is significantly slower and your script will be easier to write properly.**\n",
    "\n",
    "Note: You should have at least 6 objectives, so at least 1 objective per device. If you want to run multiple objectives on the same device, you can specify the ``rank_per_objective`` in the `ObjectiveFunction` keywords. By default, the initializer will assign different ranks for each sub-objective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
