\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[export]{adjustbox}[2011/08/13]
\usepackage{float}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{fullpage}

\hypersetup{colorlinks=true}

% shortcuts for covariant basis vectors
\newcommand{\er}{{\mathbf e}_{\rho}}
\newcommand{\ev}{{\mathbf e}_{\vartheta}}
\newcommand{\ez}{{\mathbf e}_{\zeta}}

\bibliographystyle{ieeetr}

\title{APC 524 Design Document}
\author{Daniel Dudt, Dario Panici, Evan Yerger}
\date{December 15, 2020}

\begin{document}

\maketitle

\section{Background}

\subsection{Motivation}

Determining the equilibrium of a plasma is crucial for the design and operation of magnetic confinement fusion reactors.
Equilibrium calculations are used for understanding basic plasma physics, interpreting diagnostic data from experiments, running real-time control systems to stabilize the plasma, and for optimizing the design of future machines.
Most mainstream magnetic confinement concepts for controlled fusion involve toroidal reactors, such as the tokamak and stellarator.
The tokamak is characterized by toroidal symmetry, while the stellarator does not have an ignorable coordinate and is fully ``three-dimensional''.
The nonlinear partial differential equations that describe an equilibrium are computationally challenging to solve, especially for the complicated geometries of stellarators.
Existing codes such as VMEC \cite{Hirshman1983} are expensive to run and do not always converge to the desired result, making them poorly equipped for future progress.
DESC \cite{Dudt2020} is a modern code designed to meet the increasing demands of advanced stellarator performance, and the goal of this project is to make significant contributions to the development of DESC.

\subsection{Theory}
\label{sec:theory}

Ideal magnetohydrodynamics (MHD) is a single-fluid model of plasma.
It describes the equilibrium of a static plasma through a force balance equation, along with Amp\`ere's and Gauss's laws:
%
\begin{subequations}
  \label{eq:equil}
  \begin{align}
    \label{eq:momentum}
    \mathbf{J} \times \mathbf{B} &= \nabla p \\
    \label{eq:Ampere}
    \nabla \times \mathbf{B} &= \mu_0 \mathbf{J} \\
    \label{eq:Gauss}
    \nabla \cdot \mathbf{B} &= 0.
  \end{align}
\end{subequations}
%
Here $\mathbf{J}$ is the current density, $\mathbf{B}$ is the magnetic field, $p$ is the plasma pressure, and $\mu_0$ is the magnetic constant.
Combining the force balance (\ref{eq:momentum}) and  Amp\`ere's Law (\ref{eq:Ampere}), a force balance error $\mathbf{F}$ can be defined as
%
\begin{equation}
  \label{eq:F}
  \mathbf{F} \equiv \frac{1}{\mu_0} \left( \nabla \times \mathbf{B} \right) \times \mathbf{B} - \nabla p = F_\rho \nabla\rho + F_\beta \mathbf{\beta} = \mathbf{0}
\end{equation}
%
where $\mathbf{\beta} \equiv B^\zeta \nabla \vartheta - B^\vartheta \nabla \zeta$.
The flux coordinate system $(\rho,\vartheta,\zeta)$ is a specific choice that makes the magnetic field lines ``appear straight'' to simplify calculations, and is related to the usual toroidal coordinates $(R,\phi,Z)$ as shown in Figure \ref{fig:coords}.
Equation (\ref{eq:F}) is a system of nonlinear partial differential equations (PDEs) and it must be satisfied throughout the entire plasma volume when in equilibrium.
Using Gauss's law (\ref{eq:Gauss}) and assuming that nested flux surfaces exist $\mathbf{B}\cdot\nabla\rho=B^\rho=0$, the magnetic field can be expressed in the following contravariant form of the flux coordinate system $(\rho,\vartheta,\zeta)$:
%
\begin{equation}
  \label{eq:B}
  \mathbf{B} = B^\vartheta \ev + B^\zeta \ez = \frac{\partial_\rho \Psi}{2\pi \sqrt{g}} \left( \iota \ev + \ez \right).
\end{equation}
%
Here $\Psi$ is the toroidal magnetic flux and $\iota\equiv d\vartheta/d\zeta = B^\vartheta/B^\zeta$ is the rotational transform.
The covariant basis vectors $\ev$ and $\ez$ and the jacobian of the coordinate system $\sqrt{g}$ are known from the shapes of the flux surfaces: $R(\rho,\vartheta,\zeta)$ and $Z(\rho,\vartheta,\zeta)$.
Solving the force balance given in (\ref{eq:F}) subject to a magnetic field of the form given in (\ref{eq:B}) will satisfy all of the MHD equilibrium conditions provided in (\ref{eq:equil}).
The actual scalar equations that get minimized are
%
\begin{subequations}
  \label{eq:f}
  \begin{align}
    f_\rho(R,Z) &= F_\rho \lVert\nabla\rho\rVert_2 \sqrt{g} \Delta\rho\Delta\vartheta\Delta\zeta \text{sign}\left(\nabla\rho\cdot\er\right) \\
    f_\beta(R,Z) &= F_\beta \lVert\mathbf{\beta}\rVert_2 \sqrt{g} \Delta\rho\Delta\vartheta\Delta\zeta \text{sign}\left(\mathbf{\beta}\cdot\ev\right) \text{sign}\left(\mathbf{\beta}\cdot\ez\right)
  \end{align}
\end{subequations}
%
along with additional equations to enforce the boundary conditions.
This is known as an ``inverse formulation'' because the toroidal coordinates are solved for in terms of the flux coordinates, which are treated as the independent variables.
Calculating the equilibrium magnetic field is equivalent to determining the transformation between these two coordinate systems.

The PDEs are discretized using pseudospectral methods.
The flux surfaces are represented by the coefficients of a global Fourier-Zernike basis set of the form:
%
\begin{subequations}
	\begin{align}
	\label{eq:R_basis}
	R(\rho,\vartheta,\zeta) &= \sum_{n=-N}^{N} \sum_{m=-M}^{M} \sum_{l\in L} R_{lmn} \mathcal{Z}^{m}_{l}(\rho,\vartheta) \mathcal{F}^{n}(\zeta) \\
	\label{eq:Z_basis}
	Z(\rho,\vartheta,\zeta) &= \sum_{n=-N}^{N} \sum_{m=-M}^{M} \sum_{l\in L} Z_{lmn} \mathcal{Z}^{m}_{l}(\rho,\vartheta) \mathcal{F}^{n}(\zeta)
	\end{align}
\end{subequations}
%
where $\mathcal{Z}^{m}_{l}$ is the Zernike polynomial with radial mode $l$ and azimuthal mode $m$, $\mathcal{F}^{n}$ is a Fourier component with wave number $n$, and $L = |m|, |m|+2, |m|+4, \ldots, 2 M - |m|$.
From the state vector of coefficients $\mathbf{x} = [R_{lmn}, Z_{lmn}]^T$, the values and partial derivatives of $R(\rho,\vartheta,\zeta)$ and $Z(\rho,\vartheta,\zeta)$ are transformed to physical space at a set of collocation points.
All of the nonlinear calculations involved to compute (\ref{eq:f}) are performed in physical space at these nodes, resulting in a residual vector $\mathbf{f} = [f_\rho, f_\beta]^T$.
Starting from an initial guess, DESC computes the equilibrium solution by finding the flux surface geometry that minimize these errors on a given grid of collocation points: $\mathbf{f}(\mathbf{x}) \approx \mathbf{0}$.
This optimization process is performed with a quasi-Newton method, and will be referred to as the ``inner loop'' of the DESC algorithm.
The ``outer loop'' performs a sequence of these optimizations with different input parameters, and can perturb the previous solution to give a good initial guess for the next optimization step with the new inputs.
For example, this outer loop can be used to increase the numerical resolution from a crude initial solution to one with many spectral modes.
Another application is to perform scans in solution space over a physics parameter such as pressure, by starting from a vacuum solution and then solving for the equilibrium at increasingly higher pressures.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth,center]{./figs/coordinates.pdf}
	\caption{Toroidal coordinate system $(R,\phi,Z)$ and the flux coordinates $(\rho,\vartheta,\zeta)$.}
	\label{fig:coords}
\end{figure}

\section{Project Goals}

\subsection{Initial State}

Before undertaking this project, DESC already existed as an open-source Python software package.
The user interface was to create an input file detailing all of the solver parameters, and then pass that input file as a command line argument.
The user could also pass flags to plot the results, but this output was only preset routines without much opportunity for customization.
Internally, the DESC algorithm was implemented sequentially with a functional rather than class structure.
Although the functions were well documented, each had a unique call signature and there was a lack of a common interface between different parts of the code.
New features were added to the code by creating another option in the input file format, and handling the new cases with if-else logic in the main driver script.

DESC relies on other software packages to outsource some functionality.
The NumPy \cite{NumPy} library is used to handle and vectorize all array operations in the system of equations.
Initially, all of the optimization routines for the inner loop were provided by the SciPy \cite{SciPy} optimization library.
Many of these routines rely on information of how the objective function changes with respect to state variables, which is encoded in the Jacobian matrix $\frac{\partial\mathbf{f}}{\partial\mathbf{x}}$.
This information is also needed to perform the outer loop perturbations, so it is important for DESC to compute the Jacobian matrix quickly and accurately.
This is accomplished with the use of JAX \cite{JAX}, an open source machine learning package for Python.
JAX provides automatic differentiation of arbitrary Python functions by overloading NumPy operations, as well as just-in-time (JIT) compilation and optimization for speed-up on repeated function calls.
It also allows for operations to be computed on a GPU, which can greatly accelerate the matrix-vector operations necessary for the optimization algorithm.
The initial state of the code had JAX implemented, but was disorganized about when it should be used over regular NumPy operations.

\subsection{Goals}

While DESC was functional in its initial state, it did not have a unified or high-level class structure organization to it.
It also was not extensively covered by testing, had not been thoroughly profiled for speed optimization, and lacked certain features that would make it more useful to the user.
With those shortcoming in mind, the aim of this project was to improve DESC in the following ways:
%
\begin{enumerate}
\item Refactor the code into a modular class structure
\item Expand the coverage of the existing testing suite
\item Profile the code to identify bottlenecks and explore optimization options
\item Extend the plotting capabilities to provide more solution visualization capabilities
\end{enumerate}

As mentioned in the previous section, the previous version of DESC had very minimal class structure.
This resulted in cumbersome control logic and unclear interfaces between different parts of the code.
Our primary goal of this project is to refactor DESC into a class structure that takes advantage of object-oriented programming.
This improvement will streamline the code and provide a consistent application programming interface (API) for adding new functionality as users expand the software to meet additional applications.
The new modularity will also make it easier to perform unit testing to ensure that the code is implemented properly and returns the desired output.
The existing continuous integration (CI) automated testing suite only covered 22\% of the DESC code, and our goal was to increase this converage to over 50\%.
Computational efficiency is also essential for DESC, since it was developed in the hope of finding stellarator equilibria faster than other codes.
Once the major refactoring was complete, we planned to profile the code to identify the bottlenecks and pursue any opportunities for optimization.
Finally, we also intended to create a class responsible for plotting.
Accurate solutions are only useful if they can be viewed, and the goal of this effort was to provide the user with a more flexible and interactive analysis tool.

\section{Design}

\subsection{Software Architecture}

The final architecture of the refactored DESC code is represented by the Unified Modeling Language (UML) diagram in Figure \ref{fig:DESC_UML}.
At the core of the design is the \texttt{Configuration} class, which acts as a container to store all of the spectral coefficients that describe a plasma state and their corresponding spectral basis sets.
The \texttt{Equilibrium} class inherits from \texttt{Configuration}, and uses the decorator pattern to add more information about how the equilibrium solution was solved such as the objective function that was minimized and the optimization method used.
The \texttt{Equilibrium} attributes get updated when the equilibrium is solved in each inner loop, but it also contains another \texttt{Configuration} attribute to hold the initial guess.
\texttt{EquilibriaFamily}, which inherits from \texttt{MutableSequence}, is used as a container to store the \texttt{Equilibrium} for each outer loop iteration.

\texttt{ObjectiveFunction} is an Abstract Base Class (ABC) that represents the objective function $\mathbf{f}(\mathbf{x})$ to be minimized.
Section \ref{sec:theory} only outlined one such function for the equilibrium force error, but there could be other equivalent definitions for equilibrium (such as minimizing the plasma energy) or other physical quantities of interest that need to be optimized.
The \texttt{ObjectiveFunctionFactory} provides a factory design method to systematically determine which child of \texttt{ObjectiveFunction} to use.
This objective function would be minimized by an optimization object with a very similar structure: an \texttt{OptimizerFactory} will return an instance of an ABC \texttt{Optimizer} class that represents different optimization methods.
This has not been implemented in the code yet because the SciPy optimization library is still being used, but the planned design is included in the UML in red.

Another major component of the design is the \texttt{Transform} class, which is responsible for transforming spectral coefficients to real space and fitting data to a spectral basis.
This is needed whenever the \texttt{Configuration} data is used, such as during the evaluation of an objective function or while plotting the state of the plasma.
A \texttt{Transform} object is defined by a \texttt{Grid} and a \texttt{Basis}.
The \texttt{Basis} is an ABC that represents a set of basis functions such as the Fourier-Zernike basis from (\ref{eq:R_basis}) and (\ref{eq:Z_basis}), a double Fourier series to represent the boundary surface, or a power series to describe the pressure profile.
The \texttt{Grid} represents a set of collocation points, and is intended to act as an abstract class but can be instatiated directly to create a grid of arbitrary nodes.

The outer loop is designed to be handled by the \texttt{EquilibriumSolver} class, which will be responsible for calling the factory methods at each iteration, updating the transforms as the resolution changes, and perturbing the solutions between iterations.
This functionality still lives in a script, but has been streamlined to work with the new interface and will eventually be updated into the proposed class structure.
There are several other classes that are necessary to achieve the desired modularity of the code, and can be seen in Figure \ref{fig:DESC_UML}.

\subsection{Input \& Output}

A new interface for the input and output (IO) of these class objects was also developed.
This design is particularly useful for saving and loading the solutions contained in an \texttt{EquilibriaFamily}, but the interface is intentionally general for any class object.
Any object we want to make savable inherits from the ABC \texttt{IOAble}, which includes methods to save and initialize the object from a file.
Child classes need only specify a method to initialize from initialization arguments (i.e. initializing from scratch), a list of attributes to save and load, and a dictionary of classes it may need to initialize on the fly during a load from file.
This architecture was chosen after our initial idea resulted in circular import errors:
either the objects could depend on the IO in some way or the IO could depend on the objects in some way, but both could not happen while keeping the IO functions and objects in different modules.
We decided to have the objects inherit from the IO, as it would allow for a homogeneous and simple interface when saving and loading objects.

We also altered the IO back end code significantly towards a number of goals: a homogeneous interface across file formats, protecting read/write permissions, and less code reproduction.
Starting with an ABC \texttt{IO}, which includes methods handling how all files will be treated, we specify that files should be closed on garbage collection, and files of the specified type should be opened if the class constructor is passed a file path.
Classes specifying IO operations specific to file-format, like opening files and creating sub directories inherit directly from \texttt{IO}.
Parallel to this, we introduced the abstract base classes \texttt{Reader} and \texttt{Writer}, which specify the interface for any \texttt{IO} class that reads from or writes to file, respectively.
The utility of this inheritance structure, shown in Figure \ref{fig:EquilIO_UML}, is that one only needs to specify a file format wrapper for \texttt{IO} and read or write functions to have a reader or writer that can be hot-swapped for any other.

\subsection{User Interface}

The user interface is generally split into two parts: one computes an equilibrium from command line arguments; the other to plot solutions from saved files (generated by the solver).
When calculating a solution, the user must call the program with the input filename as an argument.
Other optional arguments may be included and are detailed in the existing documentation.
The command line arguments and input file are parsed, and the required instances of the class objects will be created in order to solve.
A solution algorithm is called as a method of the EquilibriaFamily class, which creates new Equilibrium objects inside of it and saves aspects of the solution to the output file, as well as uses the linked EquilibriumSolver object to solve the problem.
Another envisioned use of the code is in an interactive sense, where the user could instantiate an Equilibrium or EquilibriaFamily from an input file, and then use the solve method of these classes to compute the solutions.

Once a solution has been found and an output file saved, the user can then instantiate a \texttt{Plot} class with the name of the output file.
Methods of this class are called to plot specified parts of the solution (magnetic field, flux surfaces, etc) for specified domains (1-D profiles, 2-D plots at a given toroidal cross-section, etc) at a specified iteration of the outer loop.
In this way, the user can use the Plot class to visualize not only the final result but also to see intermediate solutions with different input parameters, which are stored as Equilibrium objects inside of an EquilibriaFamily.

\begin{figure}[!h]
	\includegraphics[width=\textwidth,center]{figs/DESC_UML.pdf}
	\caption{UML diagram of the improved DESC software architecture. Classes in green have already been implemented; classes in red are planned.}
	\label{fig:DESC_UML}
\end{figure}

\begin{figure}[!h]
	\includegraphics[width=0.8\textwidth,center]{figs/EquilibriumIO_UML.pdf}
	\caption{UML Diagram for the new Eqiulibrium IO setup.}
	\label{fig:EquilIO_UML}
\end{figure}

\section{Development Process}

\subsection{Git Workflow}

For our project, we decided to go with the git workflow that uses infinite, parallel development and master branches.
The idea of the workflow is to branch from \texttt{master} to work on feature branches, then merge those into \texttt{dev} where the testing takes place.
Then, once the tests have passed, the feature branch is merged back into \texttt{master}.

This works well when the feature branches are all independent of each other, so merge conflicts on \texttt{dev} are minimized.
However, in our project we were refactoring an existing code base and a lot of our feature branches had some sort of inter-dependence, especially at the start.
A case of this is in the creation of the \texttt{Transform} class that is used as the base class for the coordinates at which we evaluate our objective functions.
We initially each made separate feature branches off of \texttt{master} with a defined refactoring task for each branch.
But, when it came time to merge the branches back into\texttt{master}, we realized that the \texttt{transform} branch, where the \texttt{Transform}, \texttt{Grid}, and \texttt{Basis} classes were created and other code was edited to work with them, touched many parts of the other branches' files.
This created a headache when it came time to merge the \texttt{transform} branch into \texttt{dev}, as not only merge conflicts had to be resolved, but also other working parts from other feature branches were broken.

How we ended up resolving this issue was to first merge the other, less broadly-changing feature branches into \texttt{master}.
Then, from the \texttt{transform} branch, we cherry-picked the latest commits from \texttt{master} into \texttt{transform}.
We could then resolve merge conflicts locally on the \texttt{transform} branch so it would play nice with the other branch commits.
This allowed us to keep the \texttt{dev} branch strictly for testing and not for bug-fixing commits.
So, we were able to modify the other necessary parts of the code that enabled it to run with the \texttt{Transform} classes, and then merged everything back to master without conflicts.

From this experience, we learned that the infinite and parallel \texttt{dev} and \texttt{master} workflow works best when feature branches are smaller in scope and are merged back to master often.
This way, any individual feature branch does not fall behind the master branch, and each feature branch can more easily be independent of each other.
Another thing we learned as we used this workflow was that the \texttt{dev} branch should be used only for testing.
Finding bugs on \texttt{dev} and then fixing them by committing code to \texttt{dev} seemed fine at first.
However, when we would go to make further changes on our feature branches, we would realize that some bug we fixed on \texttt{dev} was still present on the feature branch.
This would then require us to have to re-commit the same bug fix on the feature branch.
Then when we wanted to test the feature branch by merging it into \texttt{dev} before submitting a pull request into \texttt{master}, we would encounter confusing merge conflicts due to having fixed the bug separately on both \texttt{dev} and on the feature branch.
Thus, we learned the hard way that the \texttt{dev} branch should never be advanced alone but rather by merging feature branches, and all work and fixes should be done on feature branches to keep all branches up-to-date on bug fixes.

\subsection{Continuous Integration}

The continuous integration (CI) workflow with automated testing helped us catch bugs as new code was developed.
In our requirements file we had initially listed support for the latest version of JAX, version 0.2.5, as a remnant from the original DESC repository when we forked it.
JAX is still being actively developed and there have been major changes in the past year.
When pushing changes to the new \texttt{Transform} class structure that relies heavily on the use of \texttt{jax.numpy} arrays, the new changes were passing the tests on our local computers without JAX but failing on the virtual machines that were running with JAX.
This problem was puzzling because JAX is intended to replicate most of the usual numpy operations.
Around the same time, an independent user of the code had also reported a problem with running JAX on the original DESC repository.
It turned out that some of the operations we were using were no longer supported in the newer version of JAX, and reducing the installation requirement to version 0.1.77 resolved the issue.
The lesson learned was that maintaining compatibility with other software packages can be laborsome, but frequent testing (from both automated tests and beta users) can help catch problems when they arise.

\section{Profiling \& Optimization}
\label{sec:profiling}

Once a stable version of the refactored code was reached, we performed profiling to measure its performance.
Although DESC is intended to be primarily run with JAX on large clusters that have multiple GPUs, the profiling was performed on a CPU without JAX.
The JIT-ed code is more difficult to profile since the compiled functions are not executed as originally written, so working without JAX allowed us to use conventional python profiler tools.
This represents the slowest-case scenario for running DESC, but is not irrelevant for real applications -- some users may wish to run computations on their personal laptop.
We assumed that any performance gains made on this setup would also benefit other architectures because JAX only adds overhead to the underlying NumPy operations, and GPU parallelization is still limited by the serial processes of each thread.
The wall time to execute DESC depends strongly on the particular inputs chosen, since the dimension of the system of equations scales with the spectral resolution.
For these profiling tests, a stellarator input with 8 poloidal Fourier modes and 2 toroidal Fourier modes were used, with 100 inner loop iterations in a single outer loop step.
For reference, the total run time for this test case was about two minutes.

At a high level, the DESC algorithm has two major components: pre-computation of the spectral transform matrices, and the inner loop optimization.
The transform matrices are built by evaluating basis functions on a given grid, and the optimization loop is repeatedly calling the objective function.
Within the objective function itself, there are two components: the equilibrium force balance errors, and the errors in satisfying the boundary conditions.
At the spectral resolution of the reference case, each of these components consumes a roughly equal portion of the total objective function evaluation time.
cProfile was used to identify which sub-functions were the bottleneck for the overall algorithm, and then the line profiler lprun was used to determine the most expensive operations within those functions.

We discovered that the single function taking up the most computation time was the one responsible for computing the coordinate system jacobian, which is calculated from the triple product $\sqrt{g} = \er\cdot\ev\times\ez$ and gets called each time the objective function is evaluated.
The cross-product, called by \texttt{jax.numpy.cross(a, b)}, is a relatively expensive operation because it involves manipulating multidimensional arrays.
This vector algebra was easily avoided by writing out the triple product explicitly in the code, reducing all of the operations to element-wise multiplication and addition.
This reduced the computation time of the equilibrium force errors by 36\% and the total evaluation time of the objective function by 20\%, as shown in Figure \ref{fig:compute_time_opt}.
Writing out the triple product explicitly does make the code somewhat less human-readable, but it does not add many extra lines of code and is certainly worth doing for the notable speedup.

The next greatest bottleneck after the jacobian terms was Fourier basis evaluation.
This function gets called when building the transform matrices, and also when evaluating the boundary condition errors in the objective function since that transformation cannot be pre-computed.
In the original version of this function, the Fourier series was written in the complex notation $e^{im\theta}(im)^d$, where $d$ is the required order of derivative with respect to $\theta$.
Line profiling revealed that the differentiation step was taking a substantial amount of time, but was not always necessary.
The derivatives are needed in the transform matrices that can be pre-computed, while the objective function that gets called repeatedly only evaluates the Fourier series without differentiating.
This excessive operation was avoided by re-writing the function to evaluate the derivatives recursively, so that the base case of $d=0$ does not waste time differentiating.
Additional performance gains were made by replacing the complex format with all real values, and changing how the two-dimensional arrays were formed.
These edits reduced the computation time of the boundary conditions errors by 19\% and the total evaluation time of the objective function by 10\%, also shown in Figure \ref{fig:compute_time_opt}.
Since the Fourier basis evaluation is also called while pre-computing the transform matrices, this also reduced the time to build the Fourier-Zernike transformations by 36\% as shown in Figure \ref{fig:compile_time_opt}.
The build process is now dominated by the Jacobi polynomial evaluations, which comprise the radial terms of the Zernike basis functions (see Figure \ref{fig:compile_time_rel}).

With both of these optimizations combined, the time to compute the objective function was reduced by 28\% from about 4.8 ms to 3.4 ms.
The equilibrium force balance errors and boundary condition errors still take roughly the same amount of time to compute, as they did in the initial reference version (see Figure \ref{fig:compute_time_rel}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth,center]{./figs/compute_time_opt.png}
	\caption{Reduction in execution time to compute the objective function, relative to the original code, for different stages of optimization.}
	\label{fig:compute_time_opt}
\end{figure}
%
\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth,center]{./figs/compile_time_opt.png}
	\caption{Reduction in execution time to evaluate the Fourier-Zernike basis function, relative to the original code, for different stages of optimization.}
	\label{fig:compile_time_opt}
\end{figure}
%
\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth,center]{./figs/compile_time_rel.png}
	\caption{Relative portion of time to evaluate the Fourier-Zernike basis function spent in each subfunction, for different stages of optimization.}
	\label{fig:compile_time_rel}
\end{figure}
%
\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth,center]{./figs/compute_time_rel.png}
	\caption{Relative portion of time to compute the objective function spent in each subfunction, for different stages of optimization.}
	\label{fig:compute_time_rel}
\end{figure}

\section{Future Work}

\subsection{Finish Realization of Object-Oriented Design}

The most immediate future work for this project would be to complete the refactoring of the code into an object-oriented design.
The main part of the code that remains in a functional implementation is the outer loop solver.
While the refactoring we completed did increase the legibility of the outer loop solver function, there are still aspects that would benefit from being modularized.
This would come in the form of creating the \texttt{EquilibriumSolver} and \texttt{Optimizer} classes from the UML diagram, which would handle the logic of the inner-outer loop optimization algorithm.
We foresee the most difficulty in this task coming from deciding how to split the necessary steps and control logic across the respective objects.
For example, in the outer loop, a new \texttt{Equilibrium} must be created and perturbed, in order to then be sent into the inner optimization loop.
Should the \texttt{EquilibriumSolver} object be able to create new \texttt{Equilibrium} objects, even though it is not directly connected to an \texttt{Equilibrium}?
Or would this be better handled by \texttt{EquilibriaFamily}?
We have in our UML diagram an outline of what we think is the best to approach, but it is the concrete answers to these questions that we will need to decide in order to finish the implementation of our complete design.

\subsection{Expand Testing Suite}

While we did increase the percentage of code covered by tests by roughly 20\%, there is still a lot of room for improvement.
Increasing the modularity of the code helped us to more easily implement unit tests for the lower level, simpler components.
Though there are still simple classes left for us to cover with unit tests, among what is remaining are the classes that take these simpler objects and use them in a more complex way to return some physically meaningful quantites.
We have two goals to improve testing in the future, given this complexity.

The first is to have a broader integration testing suite, where we test the overall output of our code against analytically solvable solutions.
While this sort of testing suite cannot narrow down issues to specific objects or functions, it can narrow down issues to certain types of problems.
For example, an equilibrium that is axisymmetric is much simpler to compute than a non-axisymmetric equilibrium, as they are different dimensions (2-D versus 3-D).
So, with integration testing of both types of equilibria, we would be able to at least see if problems arise only with certain types of equilibria.
Additionally, this sort of testing suite would instill confidence in the output of the code.

The second is to use the mock object features of the Python unit testing modules to contrive simple examples for these more complex classes.
This would work by allowing us to create mock objects to take the place of objects that would normally be created by reading an input file and performing intermediate calculations.
We would then be able to create simple scenarios where we could more easily check the expected output, when we have control over exactly what the inputs into the function are.

\subsection{Further Profiling \& Optimization}

A preliminary round of profiling and code optimization was performed as mentioned in Section \ref{sec:profiling}, but there is certainly more room for improvement.
Profiling is an ongoing effort, but our time was limited during this project and we decided to prioritize the code refactoring over optimization of existing code.
It would be helpful to profile additional test cases with higher spectral resolutions to understand how the relative bottlenecks scale with the dimensionality of the system.
These same tests then need to be reproduced with JAX in use to check if there are opportunities specific to their overloading of the usual NumPy operations, which will have to be done using the TensorBoard profiler.
We also need to determine when it is advantageous to JIT functions and optimize the code to reduce those compile times.
Another need is to profile on different computer architectures, including with GPUs.
DESC currently has some GPU compatibility and basic parallelization, but this avenue has not been explored in much detail yet.
Finally, work is needed to optimize memory management.
The Jacobian matrix calculations can consume large amounts of memory at high resolutions, and storing this data could be especially problematic when running on GPUs.
We should explore potential solutions to remedy this, such as splitting up the Jacobian and evaluating it on multiple GPUs in parallel.

\bibliography{sources}

\end{document}
