{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# How to use Multiple Devices\n",
    "\n",
    "In this tutorial, we will see how to use multiple devices to run DESC. This will make the optimization problem scalable to computing clusters.\n",
    "\n",
    "This tutorials will not be able to run on a Jupyter Notebook, so we will provide the content of the script here but run an underlying python script to show the results.\n",
    "\n",
    "## Solving Equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "sys.path.append(os.path.abspath(\"../../../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_device = 4\n",
    "from desc import set_device, _set_cpu_count\n",
    "\n",
    "# These will be used for diving the single CPU into multiple virtual CPUs\n",
    "# such that JAX and XLA thinks there are multiple devices\n",
    "# Note that this is just to trick JAX. Since JAX can already use multiple core and threads\n",
    "# for single CPU, this will not give a speedup. This is just to test the code\n",
    "_set_cpu_count(num_device)\n",
    "set_device(\"cpu\", num_device=num_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 4 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.93 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.93 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.93 GB available memory\n",
      "\t CPU 3: TFRT_CPU_3 with 7.93 GB available memory\n"
     ]
    }
   ],
   "source": [
    "from desc.backend import print_backend_info\n",
    "\n",
    "print_backend_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "\n",
    "from desc import _set_cpu_count, set_device\n",
    "\n",
    "# ====== Using CPUs ======\n",
    "num_device = 4\n",
    "# These will be used for diving the single CPU into multiple virtual CPUs\n",
    "# such that JAX and XLA thinks there are multiple devices\n",
    "# If you have multiple CPUs, you don't need to call `_set_cpu_count`\n",
    "_set_cpu_count(num_device)\n",
    "set_device(\"cpu\", num_device=num_device)\n",
    "\n",
    "# ====== Using GPUs ======\n",
    "# When we have multiple processing using the same devices (for example, 3 processes\n",
    "# using 3 GPUs), each process will try to pre-allocate 75% of the GPU memory which will\n",
    "# cause the memory allocation to fail. To avoid this, we can set the memory fraction\n",
    "# to 1/(num_device + 2) which will allow each process to allocate 1/(num_device + 2) of\n",
    "# the GPU memory. This is a bit conservative, but if a process needs more memory, it can\n",
    "# allocate more memory on the fly.\n",
    "#\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = str(1 / (num_device + 2))\n",
    "# set_device(\"gpu\", num_device=num_device)\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "from desc import config as desc_config\n",
    "from desc.backend import print_backend_info, jax\n",
    "from desc.examples import get\n",
    "from desc.objectives.getters import (\n",
    "    get_fixed_boundary_constraints,\n",
    "    get_parallel_forcebalance,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rank = MPI.COMM_WORLD.Get_rank()\n",
    "    size = MPI.COMM_WORLD.Get_size()\n",
    "    if rank == 0:\n",
    "        print(f\"====== TOTAL OF {size} RANKS ======\")\n",
    "\n",
    "    # see which rank is running on which device\n",
    "    # Note: JAX has 2 functions for this: `jax.devices()` and `jax.local_devices()`\n",
    "    # `jax.devices()` will return all devices available to JAX, while `jax.local_devices()`\n",
    "    # will return only the devices that are available to the current process. This is\n",
    "    # useful when you have multiple processes running on multiple nodes and you want\n",
    "    # to see which devices are available to each process.\n",
    "    if desc_config[\"kind\"] == \"gpu\":\n",
    "        print(\n",
    "            f\"Rank {rank} is running on {jax.local_devices(backend=\"gpu\")} \"\n",
    "            f\"and {jax.local_devices(backend=\"cpu\")}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Rank {rank} is running on {jax.local_devices(backend='cpu')}\")\n",
    "    print_backend_info()\n",
    "\n",
    "    eq = get(\"HELIOTRON\")\n",
    "    eq.change_resolution(6, 6, 6, 12, 12, 12)\n",
    "\n",
    "    # this will create a parallel objective function\n",
    "    # user can create their own parallel objective function as well which will be\n",
    "    # shown in the next example\n",
    "    obj = get_parallel_forcebalance(eq, num_device=num_device, mpi=MPI, verbose=1)\n",
    "    cons = get_fixed_boundary_constraints(eq)\n",
    "\n",
    "    # Until this line, the code is performed on all ranks, so it might print some\n",
    "    # information multiple times. The following part will only be performed on the\n",
    "    # master rank\n",
    "\n",
    "    # this context manager will put the workers in a loop to listen to the master\n",
    "    # to compute the objective function and its derivatives\n",
    "    with obj as obj:\n",
    "        # apart from cost evaluation and derivatives, everything else will be only\n",
    "        # performed on the master rank\n",
    "        if rank == 0:\n",
    "            eq.solve(\n",
    "                objective=obj,\n",
    "                constraints=cons,\n",
    "                maxiter=3,\n",
    "                ftol=0,\n",
    "                gtol=0,\n",
    "                xtol=0,\n",
    "                verbose=3,\n",
    "            )\n",
    "\n",
    "    # if you put a code here, it will be performed on all ranks\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yigit/miniconda3/envs/mpi/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 4 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.86 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.86 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.86 GB available memory\n",
      "\t CPU 3: TFRT_CPU_3 with 7.86 GB available memory\n",
      "====== TOTAL OF 4 RANKS ======\n",
      "Rank 0 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 4 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.86 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.86 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.86 GB available memory\n",
      "\t CPU 3: TFRT_CPU_3 with 7.86 GB available memory\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Rank 2 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 4 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.84 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.84 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.84 GB available memory\n",
      "\t CPU 3: TFRT_CPU_3 with 7.84 GB available memory\n",
      "Rank 3 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 4 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.84 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.84 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.84 GB available memory\n",
      "\t CPU 3: TFRT_CPU_3 with 7.84 GB available memory\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Putting objective force on device 1\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Putting objective force on device 2\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Putting objective force on device 3\n",
      "Building objective: lcfs R\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "Building objective: lcfs Z\n",
      "Building objective: fixed Psi\n",
      "Building objective: fixed pressure\n",
      "Building objective: fixed iota\n",
      "Building objective: fixed sheet current\n",
      "Building objective: self_consistency R\n",
      "Building objective: self_consistency Z\n",
      "Building objective: lambda gauge\n",
      "Building objective: axis R self consistency\n",
      "Building objective: axis Z self consistency\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Timer: Objective build = 987 ms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Timer: LinearConstraintProjection build = 4.35 sec\n",
      "Number of parameters: 609\n",
      "Number of objectives: 15000\n",
      "Timer: Initializing the optimization = 5.39 sec\n",
      "\n",
      "Starting optimization\n",
      "Using method: lsq-exact\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : jvp_scaled_error\n",
      "Rank 2 : jvp_scaled_error\n",
      "Rank 3 : jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1          5.928e+00                                    2.480e+00   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : jvp_scaled_error\n",
      "Rank 2 : jvp_scaled_error\n",
      "Rank 3 : jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       1              2          9.876e-01      4.941e+00      3.322e-01      6.448e-01   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : jvp_scaled_error\n",
      "Rank 2 : jvp_scaled_error\n",
      "Rank 3 : jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       2              3          4.419e-02      9.434e-01      2.363e-01      8.993e-02   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : jvp_scaled_error\n",
      "Rank 2 : jvp_scaled_error\n",
      "Rank 3 : jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       3              4          1.048e-02      3.370e-02      1.497e-01      3.808e-02   \n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.048e-02\n",
      "         Total delta_x: 3.604e-01\n",
      "         Iterations: 3\n",
      "         Function evaluations: 4\n",
      "         Jacobian evaluations: 4\n",
      "Timer: Solution time = 26.4 sec\n",
      "Timer: Avg time per step = 6.62 sec\n",
      "==============================================================================================================\n",
      "                                                                 Start  -->   End\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 3 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Total (sum of squares):                                      7.355e+00  -->   1.048e-02, \n",
      "Maximum absolute Force error:                                1.077e+05  -->   1.607e+04 (N)\n",
      "Minimum absolute Force error:                                1.201e-10  -->   1.374e-10 (N)\n",
      "Average absolute Force error:                                3.587e+04  -->   2.943e+03 (N)\n",
      "Maximum absolute Force error:                                8.664e-03  -->   1.293e-03 (normalized)\n",
      "Minimum absolute Force error:                                9.659e-18  -->   1.105e-17 (normalized)\n",
      "Average absolute Force error:                                2.885e-03  -->   2.367e-04 (normalized)\n",
      "Maximum absolute Force error:                                4.334e+05  -->   4.199e+04 (N)\n",
      "Minimum absolute Force error:                                1.482e-10  -->   1.459e-10 (N)\n",
      "Average absolute Force error:                                7.335e+04  -->   7.372e+03 (N)\n",
      "Maximum absolute Force error:                                3.485e-02  -->   3.377e-03 (normalized)\n",
      "Minimum absolute Force error:                                1.192e-17  -->   1.174e-17 (normalized)\n",
      "Average absolute Force error:                                5.899e-03  -->   5.929e-04 (normalized)\n",
      "Maximum absolute Force error:                                1.057e+06  -->   6.054e+04 (N)\n",
      "Minimum absolute Force error:                                1.000e-10  -->   6.288e-11 (N)\n",
      "Average absolute Force error:                                1.205e+05  -->   1.017e+04 (N)\n",
      "Maximum absolute Force error:                                8.500e-02  -->   4.869e-03 (normalized)\n",
      "Minimum absolute Force error:                                8.043e-18  -->   5.057e-18 (normalized)\n",
      "Average absolute Force error:                                9.693e-03  -->   8.179e-04 (normalized)\n",
      "Maximum absolute Force error:                                5.498e+07  -->   4.127e+05 (N)\n",
      "Minimum absolute Force error:                                5.034e-13  -->   6.121e-12 (N)\n",
      "Average absolute Force error:                                3.746e+05  -->   1.181e+04 (N)\n",
      "Maximum absolute Force error:                                4.422e+00  -->   3.319e-02 (normalized)\n",
      "Minimum absolute Force error:                                4.048e-20  -->   4.923e-19 (normalized)\n",
      "Average absolute Force error:                                3.013e-02  -->   9.495e-04 (normalized)\n",
      "R boundary error:                                            0.000e+00  -->   0.000e+00 (m)\n",
      "Z boundary error:                                            0.000e+00  -->   0.000e+00 (m)\n",
      "Fixed Psi error:                                             0.000e+00  -->   0.000e+00 (Wb)\n",
      "Fixed pressure profile error:                                0.000e+00  -->   0.000e+00 (Pa)\n",
      "Fixed iota profile error:                                    0.000e+00  -->   0.000e+00 (dimensionless)\n",
      "Fixed sheet current error:                                   0.000e+00  -->   0.000e+00 (~)\n",
      "==============================================================================================================\n",
      "Rank 1 STOPPING\n",
      "Rank 2 STOPPING\n",
      "Rank 3 STOPPING\n"
     ]
    }
   ],
   "source": [
    "!mpirun -n 4 python mpi-tutorials/mpi-eq-solve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other Objectives\n",
    "Above we used the convenience function for force balance objective, but we can also other objectives with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "sys.path.append(os.path.abspath(\"../../../\"))\n",
    "\n",
    "from desc import _set_cpu_count, set_device\n",
    "\n",
    "# ====== Using CPUs ======\n",
    "num_device = 3\n",
    "# These will be used for diving the single CPU into multiple virtual CPUs\n",
    "# such that JAX and XLA thinks there are multiple devices\n",
    "# If you have multiple CPUs, you don't need to call `_set_cpu_count`\n",
    "_set_cpu_count(num_device)\n",
    "set_device(\"cpu\", num_device=num_device)\n",
    "\n",
    "# ====== Using GPUs ======\n",
    "# When we have multiple processing using the same devices (for example, 3 processes\n",
    "# using 3 GPUs), each process will try to pre-allocate 75% of the GPU memory which will\n",
    "# cause the memory allocation to fail. To avoid this, we can set the memory fraction\n",
    "# to 1/(num_device + 2) which will allow each process to allocate 1/(num_device + 2) of\n",
    "# the GPU memory. This is a bit conservative, but if a process needs more memory, it can\n",
    "# allocate more memory on the fly.\n",
    "#\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = str(1 / (num_device + 2))\n",
    "# set_device(\"gpu\", num_device=num_device)\n",
    "\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "from desc import config as desc_config\n",
    "from desc.backend import jax, jnp, print_backend_info\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from desc.examples import get\n",
    "from desc.grid import LinearGrid\n",
    "from desc.objectives import (\n",
    "    AspectRatio,\n",
    "    FixBoundaryR,\n",
    "    FixBoundaryZ,\n",
    "    FixCurrent,\n",
    "    FixPressure,\n",
    "    FixPsi,\n",
    "    ForceBalance,\n",
    "    ObjectiveFunction,\n",
    "    QuasisymmetryTwoTerm,\n",
    ")\n",
    "\n",
    "from desc.optimize import Optimizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rank = MPI.COMM_WORLD.Get_rank()\n",
    "    size = MPI.COMM_WORLD.Get_size()\n",
    "    if rank == 0:\n",
    "        print(f\"====== TOTAL OF {size} RANKS ======\")\n",
    "\n",
    "    # see which rank is running on which device\n",
    "    # Note: JAX has 2 functions for this: `jax.devices()` and `jax.local_devices()`\n",
    "    # `jax.devices()` will return all devices available to JAX, while `jax.local_devices()`\n",
    "    # will return only the devices that are available to the current process. This is\n",
    "    # useful when you have multiple processes running on multiple nodes and you want\n",
    "    # to see which devices are available to each process.\n",
    "    if desc_config[\"kind\"] == \"gpu\":\n",
    "        print(\n",
    "            f\"Rank {rank} is running on {jax.local_devices(backend=\"gpu\")} \"\n",
    "            f\"and {jax.local_devices(backend=\"cpu\")}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Rank {rank} is running on {jax.local_devices(backend='cpu')}\")\n",
    "    print_backend_info()\n",
    "\n",
    "    eq = get(\"precise_QA\")\n",
    "    eq.change_resolution(3, 3, 3, 6, 6, 6)\n",
    "\n",
    "    # create two grids with different rho values, this will effectively separate\n",
    "    # the quasisymmetry objective into two parts\n",
    "    grid1 = LinearGrid(\n",
    "        M=eq.M_grid, N=eq.N_grid, NFP=eq.NFP, rho=jnp.linspace(0.2, 0.5, 4), sym=True\n",
    "    )\n",
    "    grid2 = LinearGrid(\n",
    "        M=eq.M_grid, N=eq.N_grid, NFP=eq.NFP, rho=jnp.linspace(0.6, 1.0, 6), sym=True\n",
    "    )\n",
    "\n",
    "    # when using parallel objectives, the user needs to supply the device_id\n",
    "    obj1 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid1, device_id=0)\n",
    "    obj2 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid2, device_id=1)\n",
    "    obj3 = AspectRatio(eq=eq, target=8, weight=100, device_id=2)\n",
    "    objs = [obj1, obj2, obj3]\n",
    "\n",
    "    # Parallel objective function needs the MPI communicator\n",
    "    # If you don't specify `deriv_mode=blocked`, you will get a warning and DESC will\n",
    "    # automatically switch to `blocked`.\n",
    "    objective = ObjectiveFunction(objs, deriv_mode=\"blocked\", mpi=MPI)\n",
    "    if rank == 0:\n",
    "        objective.build(verbose=3)\n",
    "    else:\n",
    "        objective.build(verbose=0)\n",
    "\n",
    "    # we will fix some modes as usual\n",
    "    k = 1\n",
    "    R_modes = np.vstack(\n",
    "        (\n",
    "            [0, 0, 0],\n",
    "            eq.surface.R_basis.modes[\n",
    "                np.max(np.abs(eq.surface.R_basis.modes), 1) > k, :\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    Z_modes = eq.surface.Z_basis.modes[\n",
    "        np.max(np.abs(eq.surface.Z_basis.modes), 1) > k, :\n",
    "    ]\n",
    "    constraints = (\n",
    "        ForceBalance(eq=eq),\n",
    "        FixBoundaryR(eq=eq, modes=R_modes),\n",
    "        FixBoundaryZ(eq=eq, modes=Z_modes),\n",
    "        FixPressure(eq=eq),\n",
    "        FixPsi(eq=eq),\n",
    "        FixCurrent(eq=eq),\n",
    "    )\n",
    "    optimizer = Optimizer(\"proximal-lsq-exact\")\n",
    "\n",
    "    # Until this line, the code is performed on all ranks, so it might print some\n",
    "    # information multiple times. The following part will only be performed on the\n",
    "    # master rank\n",
    "\n",
    "    # this context manager will put the workers in a loop to listen to the master\n",
    "    # to compute the objective function and its derivatives\n",
    "    with objective as objective:\n",
    "        # apart from cost evaluation and derivatives, everything else will be only\n",
    "        # performed on the master rank\n",
    "        if rank == 0:\n",
    "            eq.optimize(\n",
    "                objective=objective,\n",
    "                constraints=constraints,\n",
    "                optimizer=optimizer,\n",
    "                maxiter=3,\n",
    "                verbose=3,\n",
    "                options={\n",
    "                    \"initial_trust_ratio\": 1.0,\n",
    "                },\n",
    "            )\n",
    "\n",
    "    # if you put a code here, it will be performed on all ranks\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 3 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.86 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.86 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.86 GB available memory\n",
      "====== TOTAL OF 3 RANKS ======\n",
      "Rank 0 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 3 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.86 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.86 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.86 GB available memory\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "Building objective: QS two-term\n",
      "Precomputing transforms\n",
      "Rank 2 is running on [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2)]\n",
      "DESC version=0.13.0+1690.g7be080fd0.dirty.\n",
      "Using JAX backend: jax version=0.5.0, jaxlib version=0.5.0, dtype=float64.\n",
      "Using 3 CPUs:\n",
      "\t CPU 0: TFRT_CPU_0 with 7.85 GB available memory\n",
      "\t CPU 1: TFRT_CPU_1 with 7.85 GB available memory\n",
      "\t CPU 2: TFRT_CPU_2 with 7.85 GB available memory\n",
      "Timer: Precomputing transforms = 1.41 sec\n",
      "Building objective: QS two-term\n",
      "Precomputing transforms\n",
      "/home/yigit/Codes/DESC/desc/utils.py:562: UserWarning: Reducing radial (L) resolution can make plasma boundary inconsistent. Recommend calling `eq.surface = eq.get_surface_at(rho=1.0)`\n",
      "  warnings.warn(colored(msg, \"yellow\"), err)\n",
      "Timer: Precomputing transforms = 1.11 sec\n",
      "Putting objective QS two-term on device 1\n",
      "Building objective: aspect ratio\n",
      "Precomputing transforms\n",
      "Timer: Precomputing transforms = 1.12 sec\n",
      "Putting objective aspect ratio on device 2\n",
      "Timer: Objective build = 4.53 sec\n",
      "Building objective: force\n",
      "Precomputing transforms\n",
      "Timer: Precomputing transforms = 1.39 sec\n",
      "Timer: Objective build = 1.46 sec\n",
      "Timer: Objective build = 24.4 ms\n",
      "Timer: Eq Update LinearConstraintProjection build = 5.13 sec\n",
      "Timer: Proximal projection build = 8.77 sec\n",
      "Building objective: lcfs R\n",
      "Building objective: lcfs Z\n",
      "Building objective: fixed pressure\n",
      "Building objective: fixed Psi\n",
      "Building objective: fixed current\n",
      "Timer: Objective build = 874 ms\n",
      "Timer: LinearConstraintProjection build = 2.11 sec\n",
      "Number of parameters: 8\n",
      "Number of objectives: 911\n",
      "Timer: Initializing the optimization = 11.8 sec\n",
      "\n",
      "Starting optimization\n",
      "Using method: proximal-lsq-exact\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : proximal_jvp_scaled_error\n",
      "Rank 2 : proximal_jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1          2.011e+04                                    1.952e+02   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : proximal_jvp_scaled_error\n",
      "Rank 2 : proximal_jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       1              4          8.735e+03      1.138e+04      4.838e-02      1.104e+02   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : proximal_jvp_scaled_error\n",
      "Rank 2 : proximal_jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       2              5          1.528e+03      7.207e+03      5.365e-02      3.401e+01   \n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : proximal_jvp_scaled_error\n",
      "Rank 2 : proximal_jvp_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "       3              6          5.325e+02      9.957e+02      8.313e-02      1.565e+01   \n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 5.325e+02\n",
      "         Total delta_x: 8.950e-02\n",
      "         Iterations: 3\n",
      "         Function evaluations: 6\n",
      "         Jacobian evaluations: 4\n",
      "Timer: Solution time = 48.9 sec\n",
      "Timer: Avg time per step = 12.2 sec\n",
      "==============================================================================================================\n",
      "                                                                 Start  -->   End\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Rank 1 : compute_scaled_error\n",
      "Rank 2 : compute_scaled_error\n",
      "Rank 0 waiting to gather\n",
      "Total (sum of squares):                                      2.011e+04  -->   5.325e+02, \n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        1.813e-01  -->   7.713e-01 (T^3)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        2.150e-04  -->   1.620e-03 (T^3)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        5.169e-02  -->   2.275e-01 (T^3)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        1.978e-01  -->   8.416e-01 (normalized)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        2.346e-04  -->   1.768e-03 (normalized)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        5.640e-02  -->   2.483e-01 (normalized)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        1.161e+00  -->   1.203e+00 (T^3)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        1.945e-03  -->   7.572e-04 (T^3)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.051e-01  -->   3.026e-01 (T^3)\n",
      "Maximum absolute Quasi-symmetry (1,2) two-term error:        1.267e+00  -->   1.313e+00 (normalized)\n",
      "Minimum absolute Quasi-symmetry (1,2) two-term error:        2.122e-03  -->   8.262e-04 (normalized)\n",
      "Average absolute Quasi-symmetry (1,2) two-term error:        1.147e-01  -->   3.302e-01 (normalized)\n",
      "Aspect ratio:                                                5.996e+00  -->   7.859e+00 (dimensionless)\n",
      "Maximum absolute Force error:                                1.345e+05  -->   4.971e+04 (N)\n",
      "Minimum absolute Force error:                                8.350e+00  -->   6.376e-01 (N)\n",
      "Average absolute Force error:                                5.462e+03  -->   2.762e+03 (N)\n",
      "Maximum absolute Force error:                                9.614e-02  -->   3.554e-02 (normalized)\n",
      "Minimum absolute Force error:                                5.969e-06  -->   4.558e-07 (normalized)\n",
      "Average absolute Force error:                                3.904e-03  -->   1.974e-03 (normalized)\n",
      "R boundary error:                                            0.000e+00  -->   4.734e-19 (m)\n",
      "Z boundary error:                                            0.000e+00  -->   3.478e-18 (m)\n",
      "Fixed pressure profile error:                                0.000e+00  -->   0.000e+00 (Pa)\n",
      "Fixed Psi error:                                             0.000e+00  -->   0.000e+00 (Wb)\n",
      "Fixed current profile error:                                 0.000e+00  -->   0.000e+00 (A)\n",
      "==============================================================================================================\n",
      "Rank 1 STOPPING\n",
      "Rank 2 STOPPING\n"
     ]
    }
   ],
   "source": [
    "!mpirun -n 3 python mpi-tutorials/mpi-proximal.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Slurm for Multi-Node and Multi-Process Scripts\n",
    "\n",
    "**Note :** These instructions may differ for the cluster you are trying to use. The reason we give this example is to set some terminology for users that are not familiar with multi-node and multi-processing.\n",
    "\n",
    "**Note :** For more details, one can check Princeton University Research Computing page [here](https://researchcomputing.princeton.edu/support/knowledge-base/slurm#Multinode--Multithreaded-Jobs).\n",
    "\n",
    "One needs to use proper slurm script to run parallel code on a cluster. Here, we will give an example in which we use 2 nodes, 8 processes per node and 4 CPU cores per process. *Node* means the actual CPU chip, so we will have 2 CPUs or you can think of it as, we will have 2 computers that are connected to each other. We will have 16 processes and 64 CPU cores in total. Additionally, you can specify number of GPUs per node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=mpi-example        # create a short name for your job\n",
    "#SBATCH --nodes=2                # node count\n",
    "#SBATCH --ntasks-per-node=8      # total number of tasks per node\n",
    "#SBATCH --cpus-per-task=4        # cpu-cores per task (>1 if multi-threaded tasks)\n",
    "#SBATCH --mem-per-cpu=4G         # memory per cpu-core (4G is default)\n",
    "#SBATCH --time=00:10:00          # total run time limit (HH:MM:SS)\n",
    "#SBATCH --gres=gpu:4             # number of GPUs per node (in this case 8 GPUs in total)\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n",
    "module purge\n",
    "module load intel/2022.2.0\n",
    "module load intel-mpi/intel/2021.7.0\n",
    "\n",
    "srun python your-script.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using MPI with multiple nodes, each process will see 1 CPU, and if you requested GPUs, only the GPUs connected to that CPU will be visible to your program. With this in mind, for example, if you want to use 2 nodes, and 3 GPUs per nodes with 3 processes per node, you can use 6 objectives in this way.\n",
    "\n",
    "```python\n",
    "\n",
    "# each node will see 3 GPUs\n",
    "num_device = 3\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = str(1 / (num_device + 2))\n",
    "set_device(\"gpu\", num_device=num_device)\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "# this will run on node 1, GPU 0 (rank=0)\n",
    "obj1 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid1, device_id=0)\n",
    "# this will run on node 1, GPU 1 (rank=1)\n",
    "obj2 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid2, device_id=1)\n",
    "# this will run on node 1, GPU 2 (rank=2)\n",
    "obj3 = QuasisymmetryTwoTerm(eq=eq, helicity=(1, eq.NFP), grid=grid3, device_id=2)\n",
    "# this will run on node 2, GPU 0 (rank=3)\n",
    "obj4 = AspectRatio(eq=eq, target=8, weight=100, device_id=0)\n",
    "# this will run on node 2, GPU 2 (rank=4)\n",
    "obj5 = Objective(..., device_id=1)\n",
    "# this will run on node 2, GPU 2 (rank=5)\n",
    "obj6 = Objective(..., device_id=2)\n",
    "objs = [obj1, obj2, obj3, obj4, obj5, obj6]\n",
    "\n",
    "# Parallel objective function needs the MPI communicator\n",
    "objective = ObjectiveFunction(objs, deriv_mode=\"blocked\", mpi=MPI)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
