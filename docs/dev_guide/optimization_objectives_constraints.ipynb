{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69ed88a-4ee1-438b-b992-4f57e22613c3",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Optimization, objectives, and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa50bd6-6c18-41ff-a891-92785359fb97",
   "metadata": {},
   "source": [
    "The goal of any unconstrained optimization problem is to find the \"best\" solution or most desirable input values for a given objective function.\n",
    "In a constrained optimization problem, there is an additional set of constraints that must be satified for the solution to be of interest.\n",
    "\n",
    "DESC approaches the ideal MHD fixed-boundary equilibrium problem $\\mathbf{F}=0$ [as an optimization problem](https://desc-docs.readthedocs.io/en/latest/theory_general.html).\n",
    "That is $\\min_{\\mathbf{x} \\in \\mathcal{R}^n} \\mathbf{f}(\\mathbf{x})$ subject to a system of linear constraints $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ where the objective to be minimized is the MHD force balance error $\\mathbf{F}=\\mathbf{J}\\times \\mathbf{B} - \\nabla p$.\n",
    "\n",
    "This objective is minimized by evaluating the two components of $\\mathbf{F}$, given by $f_{\\rho}$ and $f_{\\beta}$, on a collocation grid.\n",
    "The resulting vector of residuals $\\mathbf{f} = [f_{\\rho},f_{\\beta}]$ has length equal to twice the number of grid points (colloaction nodes) since each of $f_{\\rho}, f_{\\beta}$ are evaluated at every collocation node.\n",
    "\n",
    "The two components of the force balance residuals map the state vector $\\mathbf{x}$ to the values of the residuals at the points given by the state vector: $f \\colon \\mathbf{x} ↦ f(\\mathbf{x})$. \n",
    "The state vector being minimized over  $\\mathbf{x} = [R_{lmn}, Z_{lmn}, \\lambda_{lmn}]$ is the vector of the Fourier-Zernike spectral coefficients used to describe the mapping between the toroidal $(R,\\phi,Z)$ coordinates and the computational flux coordinates $(\\rho,\\theta,\\zeta)$.\n",
    "The state vector has one of the following lengths\n",
    "- `3*eq.R_basis.num_modes` if a non-stellarator symmetric equilibrium, where the number of basis modes for R and Z are the same\n",
    "- `eq.R_basis.num_modes + 2 * eq.Z_basis.num_modes` if a stellarator-symmetric equilibrium, where $R$ has $cos(m\\theta-n\\zeta)$ symmetry, and $Z$ and $\\lambda$ have $sin(m\\theta-n\\zeta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36f11d-ebd3-4a35-90fb-d1b398704467",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives vs. constraints\n",
    "\n",
    "A typical task for DESC may involve\n",
    "- solving for a good equilibrium (minimize force balance errors) given constraints like profiles and boundaries\n",
    "- optimizing for some criteria on the solved equilibrium\n",
    "\n",
    "The first task would include `ForceBalance()` as the objective function and constriants which fix profiles and boundaries.\n",
    "A fixed-boundary equilbrium problem requires the fixed-boundary $R_b(\\theta,\\zeta),Z_b({\\theta,\\zeta})$ to be given as a linear constraint during the optimization.\n",
    "In DESC, additionally a [gauge constraint](https://desc-docs.readthedocs.io/en/latest/_api/objectives/desc.objectives.FixLambdaGauge.html) on $\\lambda$ is applied (to make it periodic), since $\\lambda$ is only defined up to an additive multiple of $2\\pi$, which constitutes another linear constraint to the problem.\n",
    "An example is shown in the section titled [solving the equilibrium](https://desc-docs.readthedocs.io/en/latest/notebooks/hands_on.html#Solving-the-Equilibrium).\n",
    "\n",
    "The second task may consider `ForceBalance()` as a constraint, so as to not throw away the work done to find a good equilibrium, and some criteria for better quasisymmetry as an objective.\n",
    "An example is shown in the section titled [triple product](https://desc-docs.readthedocs.io/en/latest/notebooks/tutorials/03_Quasi-Symmetry_Optimization.html#Triple-Product).\n",
    "This allows for searching the configuration space (combinations of parameters that define the state of plasma) for configurations with better quasisymmetry while only considering those that are still good equilibriums.\n",
    "\n",
    "As demonstrated above, the python object `ForceBalance()` of type `Objective` was used as an objective in the optimization sense in the first task and a constraint in the second task.\n",
    "There is no seperate `Constraint` type class.\n",
    "An `Objective` type object is an optimization objective if it is supplied for the `objective` argument to the `optimizer` object.\n",
    "An `Objective` type object is an optimization constraint if it is supplied for the `constraints` argument to the `optimizer` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426436c8-f966-4a68-8480-7f6d5563a690",
   "metadata": {},
   "source": [
    "## Feasible direction formulation\n",
    "\n",
    "In any case, the task given to DESC is to solve a constrained optimization problem.\n",
    "DESC deals with constrained optimization problem by using the feasible direction formulation.\n",
    "See for example [page 3 of this reference](https://www.cs.umd.edu/users/oleary/a607/607constr1hand.pdf).\n",
    "\n",
    "The geometry of this approach is as follows.\n",
    "Suppose the objective is to minimize a function $f \\colon \\mathbb{R}^n \\to \\mathbb{R}$, subject to a linear system of equations that define the constraints given by $A \\mathbf{x} = \\mathbf{b}$.\n",
    "These equations sketch a surface: $\\text{image}(A) = S \\subset \\mathbb{R}^n$ that define the set of feasible points.\n",
    "That is, any point on this surface satisfies $A \\mathbf{x} = \\mathbf{b}$.\n",
    "It is more practical to search for minima to $f$ on this surface than blindy through $\\mathbb{R}^n$.\n",
    "\n",
    "With this approach, the iteration defined by the optimization will only consider vectors that are valid candidates (they satisfy the constraints).\n",
    "Moreover, by only searching for solutions on this surface, we can reduce the constrained optimization problem\n",
    "$$\\min_{\\mathbf{x} ∈ \\mathbb{R}^n} f(\\mathbf{x}) \\; \\text{such that} \\; A \\mathbf{x} = \\mathbf{b}$$\n",
    "to an unconstrained one which can be solved with techniques like Newton iteration and least-squares.\n",
    "Moreover, each step of the iteration may be a potential solution.\n",
    "$$\\min_{\\mathbf{x} ∈ S \\subset \\mathbb{R}^n} f(\\mathbf{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55080848-eed0-4e6f-b993-d6e148db919a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Removing linear constraints by factoring\n",
    "We can limit the search space to the relavant surface by factoring the state vector into a particular component and a homogenous component: $\\mathbf{x} = \\mathbf{x}_{\\text{p}} + \\mathbf{x}_{\\text{h}}$.\n",
    "The particular component, $\\mathbf{x}_{\\text{p}}$, satisfies the constraints $A \\mathbf{x}_{\\text{p}} = \\mathbf{b}$.\n",
    "Meaning $\\mathbf{x}_{\\text{p}}$ is a vector that points from the origin to a point on the surface $S = \\text{image}(A)$.\n",
    "The homogenous component, $\\mathbf{x}_{\\text{h}}$, satisfies $A \\mathbf{x}_{\\text{h}} = \\mathbf{0}$.\n",
    "Meaning $\\mathbf{x}_{\\text{h}}$ is a vector that points from some point on $S$ to another point on $S$.\n",
    "Hence, $\\mathbf{x}_p + \\mathbf{x}_h$ lies on the surface $S$, or in the image of $A$.\n",
    "$$A \\mathbf{x} = A (\\mathbf{x}_{\\text{p}} + \\mathbf{x}_{\\text{h}}) = \\mathbf{b}$$\n",
    "\n",
    "Any $\\mathbf{x}_{\\text{h}}$ can be written as a linear combination of a nullspace basis of $A$: $\\; \\mathbf{x}_{\\text{h}} = Z \\mathbf{y}$.\n",
    "These are the vectors which parameterize the surface $S$.\n",
    "With this convention, the state variable is\n",
    "$$\\mathbf{x} = \\mathbf{x}_p + \\mathbf{Z}\\mathbf{y}$$\n",
    "and the optimization problem becomes an unconstrained search for $\\mathbf{y}$ that yields\n",
    "$$\\min_{\\mathbf{y} ∈ \\mathbb{R}^{n - m} \\subset \\mathbb{R}^n} f(\\mathbf{x}_{\\text{p}} + Z \\mathbf{y})$$\n",
    "\n",
    "The length of the vector $\\mathbf{y}$ corresponds to the number of linearly independent vectors in the nullspace of $A$, or the number of free (unfixed) parameters.\n",
    "If $A \\in \\mathbb{R}^{m \\times n}$ with rank $m$, then the length of $\\mathbf{y}$ will be $n-m$.\n",
    "Each component of $\\mathbf{y}$ corresponds to some unfixed parameter.\n",
    "As the optimizer iterates through some trajectory by changing these parameters, the optimizer searches over the surface of feasible solutions.\n",
    "\n",
    "This method is sometimes summarized as projecting away the constraints because the orthogonal projection of $\\mathbf{x} - \\mathbf{x}_p$ onto the nullspace of $A$ is $\\mathbf{x}_h$.\n",
    "If $Z$ is additionally constructed to be orthonormal, then it is easy to compute $\\mathbf{y}$ from $\\mathbf{x}$ and vice versa, a desireable quality to recover the solution to the original optimization problem from the simpler one it was reduced to.\n",
    "Recall that $Z Z^T$ is the orthogonal projection onto the nullspace of $A$.\n",
    "We have\n",
    "$$ \\begin{align*}\n",
    "     \\mathbf{x} - \\mathbf{x}_p & = \\mathbf{x}_h \\\\\n",
    "                               & = Z \\mathbf{y} \\\\\n",
    "     Z Z^T (\\mathbf{x} - \\mathbf{x}_p) & = Z (Z^T Z) \\mathbf{y} \\\\\n",
    "                                       & = Z \\mathbf{y} \\\\\n",
    "                                       & = \\mathbf{x}_h\n",
    "\\end{align*} $$\n",
    "The easy way to compute $\\mathbf{y}$, or to \"project\" the full state vector $\\mathbf{x}$ into the reduced optimization vector $\\mathbf{y}$, is:\n",
    "$$Z^T (\\mathbf{x} - \\mathbf{x}_p) = \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193e76f-4662-4610-98df-e310d89fd23a",
   "metadata": {},
   "source": [
    "### `factorize_linear_constraints`\n",
    "\n",
    "In DESC, the process discussed above is done in the `factorize_linear_constraints` function of `desc.objectives.utils`.\n",
    "This next few paragraphs will walk through the important parts of that code.\n",
    "\n",
    "A given optimization may have multiple constraints.\n",
    "The \"parallel-arrays\" convention is used to group them.\n",
    "There are dictionaries denoted $A$, $\\mathbf{x}$, and $\\mathbf{b}$ where the keys are the names of the constraints (`obj.args[0]` is the class name of the objective), and the values are the matrices associated with that constraint.\n",
    "So the constraint equations associated with a magnetic well constraint could be queried with:\n",
    "```python\n",
    "key = \"Magnetic Well\"\n",
    "A_key  = A[key]\n",
    "xp_key = xp[key]\n",
    "b_key  = b[key]\n",
    "```\n",
    "\n",
    "First, we instantiate the dictionaries and create the vectors for each $\\mathbf{x}$ of every constraint.\n",
    "The `dim_x` attribute of an `objective` is the length of the state vector $\\mathbf{x}$.\n",
    "The `dim_f` attribute is the number of objective equations or the rank of $A$ in $A \\mathbf{x} = \\mathbf{b}$ when the `objective` object is considered a constraint.\n",
    "```python\n",
    "# set state vector\n",
    "args = np.concatenate([obj.args for obj in constraints])\n",
    "args = np.concatenate((args, objective_args))\n",
    "# this is all args used by both constraints and objective\n",
    "args = [arg for arg in arg_order if arg in args]\n",
    "dimensions = constraints[0].dimensions\n",
    "dim_x = 0\n",
    "x_idx = {}\n",
    "for arg in objective_args:\n",
    "    x_idx[arg] = np.arange(dim_x, dim_x + dimensions[arg])\n",
    "    dim_x += dimensions[arg]\n",
    "\n",
    "A = {}\n",
    "b = {}\n",
    "Ainv = {}\n",
    "xp = jnp.zeros(dim_x)  # particular solution to Ax=b\n",
    "constraint_args = []  # all args used in constraints\n",
    "unfixed_args = []  # subset of constraint args for unfixed objectives\n",
    "```\n",
    "\n",
    "Then we loop through each constraint and create the matrices as discussed above.\n",
    "Note that if the target vector is fully specified, that is the length given by `dimensions[obj.target.arg]` equals the total number of available equations, then we know the target vector should be a solution to the contraints $A \\mathbf{x} = \\mathbf{b}$ and can set $\\mathbf{x}_p$ to match the target vector.\n",
    "\n",
    "Otherwise, the `else` loop is entered, and we need to actually solve for a solution to the system.\n",
    "Recall, the compute functions of `Objective` objects first compute some quantity (like $A \\mathbf{x}$), then they call the method `self._shift_scale` to subtract out the target quantity.\n",
    "In other words, the function call `obj.compute_scaled(x)` computes the value of a function of $\\mathbf{x}$ defined as $A \\mathbf{x} - \\mathbf{b}$, which we would prefer to be close to zero.\n",
    "To compute $\\mathbf{x}$, we may store the returned value of the function call: `-1 * obj.compute_scaled(x=0)`.\n",
    "\n",
    "```python\n",
    "# linear constraint matrices for each objective\n",
    "for obj in constraints:\n",
    "    if obj.fixed and obj.dim_f == dimensions[obj.target_arg]:\n",
    "        # obj.fixed is always true if the objective is linear\n",
    "        # if all coefficients are fixed the constraint matrices are not needed\n",
    "        xp = put(xp, x_idx[obj.target_arg], obj.target)\n",
    "    else:\n",
    "        unfixed_args.append(arg)\n",
    "        A_ = obj.derivatives[\"jac\"][arg](jnp.zeros(dimensions[arg]))\n",
    "        # using obj.compute instead of obj.target to allow for correct scale/weight\n",
    "        b_ = -obj.compute_scaled(jnp.zeros(obj.dimensions[arg]))\n",
    "        Ainv_, Z_ = svd_inv_null(A_)\n",
    "        A[arg] = A_\n",
    "        b[arg] = b_\n",
    "        # need to undo scaling here to work with perturbations\n",
    "        Ainv[arg] = Ainv_ * obj.weight / obj.normalization\n",
    "```\n",
    "\n",
    "Then we merge each individual constraint matrix into one block diagonal system.\n",
    "That way we can return a single optimization problem back to optimizer.\n",
    "```python\n",
    "# full A matrix for all unfixed constraints\n",
    "if len(A):\n",
    "    unfixed_idx = jnp.concatenate(\n",
    "        [x_idx[arg] for arg in arg_order if arg in A.keys()]\n",
    "    )\n",
    "    A_full = block_diag(*[A[arg] for arg in arg_order if arg in A.keys()])\n",
    "    b_full = jnp.concatenate([b[arg] for arg in arg_order if arg in b.keys()])\n",
    "    Ainv_full, Z = svd_inv_null(A_full)\n",
    "    xp = put(xp, unfixed_idx, Ainv_full @ b_full)\n",
    "```\n",
    "\n",
    "The helper function used above, `desc.utils.svd_inv_null(A)`, returns the pseudoinverse, $A^{\\dagger}$, and an orthonormal matrix $Z$ with columns that span the nullspace of A.\n",
    "We then return functions to the optimizer that compute the reduced optimization vector `x_reduced` (labeled $\\mathbf{y}$ in the math discussed above) and recover the full state vector.\n",
    "\n",
    "```python\n",
    "def project(x):\n",
    "    \"\"\"Project a full state vector into the reduced optimization vector.\"\"\"\n",
    "    x_reduced = Z.T @ ((x - xp)[unfixed_idx])\n",
    "    return jnp.atleast_1d(jnp.squeeze(x_reduced))\n",
    "\n",
    "def recover(x_reduced):\n",
    "    \"\"\"Recover the full state vector from the reduced optimization vector.\"\"\"\n",
    "    dx = put(jnp.zeros(dim_x), unfixed_idx, Z @ x_reduced)\n",
    "    return jnp.atleast_1d(jnp.squeeze(xp + dx))\n",
    "```\n",
    "\n",
    "It should be clear that the length of `x_reduced` is equal to the number of free (unfixed) parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16789fcf-99a9-47ba-8480-e628f40a74e9",
   "metadata": {},
   "source": [
    "## Rebuilding objectives\n",
    "DESC uses a iterative method to solve and optimizize equilibrium.\n",
    "Sometimes this invovles changing the resolution of an equilibrium via changing the resolution of the `grid` object belonging to that equilibrium.\n",
    "(Typlically we start from a low resolution equilibrium, and increase later).\n",
    "This means many quantities need to be recomputed on the newer grid.\n",
    "In particular the `Objective` objects that include optimization objectives and constraints need to be rebuilt, so that the values they store are computed on the newer grid.\n",
    "(See the grid tutorial if you are not familiar with the structure in which computed quantities are stored)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1e448-a8a5-4a4f-9f44-d7c3f8a24f7c",
   "metadata": {},
   "source": [
    "# todo below\n",
    "https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263199ee-3a30-4390-8487-9083853393ba",
   "metadata": {},
   "source": [
    "## `linear_objectives.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e1cc-c637-47d3-b24e-44002984608a",
   "metadata": {},
   "source": [
    "- when specifying interior surface as the fixboundary constraint, the self A becomes zernike_radial instead of 1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
