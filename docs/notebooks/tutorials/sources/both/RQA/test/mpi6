#!/bin/bash
#SBATCH --job-name=5dellabn_res_vec        # Job name
#SBATCH --output=5bn_res_vec.%j.out   # Standard output
#SBATCH --error=5bn_res_vec.%j.err    # Standard error
#SBATCH --time=01:00:00              # Walltime (hh:mm:ss)
#SBATCH --nodes=2                    # Number of nodes
#SBATCH --ntasks-per-node=4          # MPI ranks per node
#SBATCH --cpus-per-task=45          # CPU cores per MPI rank
#SBATCH --mem=300G                      # Use all memory on node
#SBATCH --mail-type=BEGIN,END,FAIL         # Notifications for job done & fail
#SBATCH --mail-user=fcastro@princeton.edu

# ---- Setup environment ----
module purge
module load anaconda3/2025.6   # adjust if different on Della
module load openmpi/gcc/4.1.6  # or whatever MPI version Della provides

# activate your conda environment (replace "desc-env" with yours)
source activate desc-ray

# Let BLAS/OpenMP use all cores on the node
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK
export JAX_PLATFORMS=cpu

NOTEBOOK="mpi6.ipynb"
EXECUTED_NOTEBOOK="mpi6_executed.ipynb"

# Step 1: Execute notebook and save outputs
echo "Executing notebook and saving outputs..."
jupyter nbconvert --to notebook --execute "$NOTEBOOK" \
    --output "$EXECUTED_NOTEBOOK" --ExecutePreprocessor.timeout=3600

# Step 2: Convert executed notebook to Python script
echo "Converting executed notebook to Python script..."
jupyter nbconvert --to script "$EXECUTED_NOTEBOOK"

# Step 3: Run Python script with MPI (1 rank per node, multi-threaded)
SCRIPT_NAME="${EXECUTED_NOTEBOOK%.ipynb}.py"
echo "Running Python script with MPI..."
mpiexec -n $SLURM_NTASKS python "$SCRIPT_NAME"

echo "Job finished."
