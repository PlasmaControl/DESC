#!/bin/bash
#SBATCH --job-name=5bn_res_vec        # Job name
#SBATCH --output=5bn_res_vec.%j.out   # Standard output
#SBATCH --error=5bn_res_vec.%j.err    # Standard error
#SBATCH --time=00:60:00              # Walltime (hh:mm:ss)
#SBATCH --nodes=4                    # Number of nodes
#SBATCH --ntasks-per-node=81          # MPI ranks per node
#SBATCH --cpus-per-task=1         # CPU cores per MPI rank
#SBATCH --mem=250G                      # Use all memory on node
#SBATCH --mail-type=BEGIN,END,FAIL         # Notifications for job done & fail
#SBATCH --mail-user=fcastro@princeton.edu

# ---- Setup environment ----
module purge
module load anaconda3/2025.6   # adjust if different on Della
module load openmpi/gcc/4.1.6  # or whatever MPI version Della provides

# activate your conda environment (replace "desc-env" with yours)
source activate desc-ray

# Let BLAS/OpenMP use all cores on the node
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK
export JAX_PLATFORMS=cpu

NOTEBOOK="mpi5.ipynb"
EXECUTED_NOTEBOOK="mpi5_executed.ipynb"

# ---- Paths ----
#NOTEBOOK="/home/fcastro/DESC/docs/notebooks/tutorials/sources/both/RQA/test/mpi5.ipynb"
#EXECUTED_NOTEBOOK="/home/fcastro/DESC/docs/notebooks/tutorials/sources/both/RQA/test/mpi5_executed.ipynb"

# ---- Step 1: Execute notebook ----
echo "Executing notebook and saving outputs..."
jupyter nbconvert --to notebook --execute "$NOTEBOOK" \
    --output "$EXECUTED_NOTEBOOK" \
    --ExecutePreprocessor.timeout=3600 \
    --allow-errors

# ---- Step 2: Convert executed notebook to Python script ----
echo "Converting executed notebook to Python script..."
jupyter nbconvert --to script "$EXECUTED_NOTEBOOK"

SCRIPT_NAME="${EXECUTED_NOTEBOOK%.ipynb}.py"

# ---- Step 3: Run Python script with MPI ----
if [ -f "$SCRIPT_NAME" ]; then
    echo "Running Python script with MPI..."
    mpiexec -n $SLURM_NTASKS python "$SCRIPT_NAME"
else
    echo "Error: Python script $SCRIPT_NAME not found. Notebook execution may have failed."
fi

echo "Job finished."
